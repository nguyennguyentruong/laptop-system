2024-07-16 19:32:33 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: crawler_app)
2024-07-16 19:32:33 [scrapy.utils.log] INFO: Versions: lxml 5.2.2.0, libxml2 2.12.6, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.3.0, Python 3.10.4 (main, Apr  4 2023, 00:21:41) [Clang 12.0.0 (clang-1200.0.32.29)], pyOpenSSL 24.1.0 (OpenSSL 3.2.2 4 Jun 2024), cryptography 42.0.8, Platform macOS-10.15.7-x86_64-i386-64bit
2024-07-16 19:32:33 [scrapy.addons] INFO: Enabled addons:
[]
2024-07-16 19:32:33 [asyncio] DEBUG: Using selector: KqueueSelector
2024-07-16 19:32:33 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-07-16 19:32:33 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
2024-07-16 19:32:33 [scrapy.extensions.telnet] INFO: Telnet Password: d1b71e12b9fa2e51
2024-07-16 19:32:33 [py.warnings] WARNING: /Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/extensions/feedexport.py:406: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

2024-07-16 19:32:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2024-07-16 19:32:33 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'crawler_app',
 'DOWNLOAD_DELAY': 4,
 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'logs/crawler_app/topcv/7769694e436f11ef98aaa8206602a7f9.log',
 'NEWSPIDER_MODULE': 'crawler_app.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_HTTP_CODES': [429, 503],
 'RETRY_TIMES': 5,
 'ROBOTSTXT_OBEY': True,
 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler',
 'SPIDER_MODULES': ['crawler_app.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
2024-07-16 19:32:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-07-16 19:32:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-07-16 19:32:33 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-07-16 19:32:33 [scrapy.core.engine] INFO: Spider opened
2024-07-16 19:32:34 [topcv] DEBUG: Resuming crawl (26 requests scheduled)
2024-07-16 19:32:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-07-16 19:32:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-07-16 19:32:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/robots.txt> (referer: None)
2024-07-16 19:32:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/nhan-vien-thiet-ke-do-hoa-designer-tai-hai-phong-tu-10-den-20-trieu/1263921.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:32:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/nhan-vien-thiet-ke-do-hoa-designer-tai-hai-phong-tu-10-den-20-trieu/1263921.html?ta_source=ITJobs_LinkDetail>
{'benefits': '- Lương/thưởng hấp dẫn theo quy định của công ty ( 10.000.000 - '
             '20.000.000VNĐ)\n'
             '- Chế độ BHXH, BHYT theo luật Lao động\n'
             '- Được hưởng các ngày nghỉ lễ, Tết theo quy định của Nhà nước\n'
             '- Được làm việc trong môi trường năng động và chuyên nghiệp, cơ '
             'hội thăng tiến cao. Làm việc với đồng nghiệp thân thiện, hỗ trợ '
             'và chia sẻ kiến thức\n'
             '- Tham gia các hoạt động teambuilding và du lịch hàng năm của '
             'công ty\n'
             '- Được tham gia các khoá đào tạo từ các chuyên gia hàng đầu về '
             'thương mại điện tử, marketing online, phầm mềm, ...',
 'company': 'Công ty Cổ phần Giải pháp phần mềm trực tuyến Việt Nam',
 'deadline': '',
 'description': '- Thiết kế/Chỉnh sửa các giao diện website theo yêu cầu; \n'
                '- Tham gia vào quá trình phát triển sản phẩm, thiết kế UI/UX '
                'cho App/Web và các sản phẩm về công nghệ; \n'
                '- Phối hợp chặt chẽ với các bộ phận liên quan để đưa ra '
                'phương án thiết kế phù hợp với sản phẩm/dịch vụ; phát huy '
                'hiệu quả công việc; \n'
                '- Thực hiện công việc dưới sự chỉ đạo của trưởng nhóm;',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/nhan-vien-thiet-ke-do-hoa-designer-tai-hai-phong-tu-10-den-20-trieu/1263921.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hải Phòng',
 'requirements': '- Có ít nhất 1 năm kinh nghiệm ở vị trí tương đương (yêu cầu '
                 'có porfolio; đính kèm link sản phẩm);\n'
                 '- Sử dụng thành thạo các phần mềm đồ họa, web như: Figma, '
                 'Adobe Photoshop;',
 'salary': '10 - 20 triệu',
 'title': 'Nhân Viên Thiết Kế Đồ Hoạ / Designer Tại Hải Phòng (Từ 10 Đến 20 '
          'Triệu)'}
2024-07-16 19:32:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/mid-java-dev/1392378.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:32:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/mid-java-dev/1392378.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY TNHH ISB VIỆT NAM',
 'deadline': '',
 'description': 'Analyze and understand existing VB.NET codebases, focusing on '
                'business logic and functionalities.\n'
                ' Translate VB.NET code into clean, well-structured Java code '
                'using Spring frameworks (Spring Boot preferred).\n'
                ' Design and document detailed design specifications for the '
                'converted Java code, ensuring maintainability and '
                'scalability.\n'
                ' Develop and implement unit tests for the converted Java code '
                'to guarantee code quality and reliability.\n'
                ' Collaborate with the development team to understand business '
                'requirements and ensure the converted code meets those needs.',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/mid-java-dev/1392378.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': '13 - 25 triệu',
 'title': 'Mid Java Dev'}
2024-07-16 19:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/devops-engineer/1406319.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:32:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/devops-engineer/1406319.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY CỔ PHẦN AHT TECH',
 'deadline': '',
 'description': '',
 'experience': '3 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/devops-engineer/1406319.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'DevOps Engineer'}
2024-07-16 19:32:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/sales-it-tieng-anh/1404576.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:32:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/sales-it-tieng-anh/1404576.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'World Fusion Vietnam Co,.Ltd',
 'deadline': '',
 'description': '',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/sales-it-tieng-anh/1404576.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Sales IT (Tiếng Anh)'}
2024-07-16 19:33:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/it-recruitment-intern/1406078.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:33:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/it-recruitment-intern/1406078.html?ta_source=ITJobs_LinkDetail>
{'benefits': '● Thu nhập = Phụ cấp thực tập + hoa hồng.\n'
             '● Phụ cấp thực tập: 1.200.000 đ/tháng (nếu làm Fulltime từ Thứ '
             '2-Thứ 6).\n'
             '● Hoa hồng: Khoản tiền thưởng cho các vị trí do bạn phụ trách có '
             '“Ứng viên nộp hồ sơ”.\n'
             '● Xác nhận thực tập cho sinh viên năm cuối.\n'
             '● Thời gian làm việc linh động sắp xếp theo thời gian biểu cá '
             'nhân.\n'
             '● Tiếp cận với thị trường tuyển dụng IT, một trong những ngành '
             'cực kỳ HOT trong thời đại công nghệ 4.0\n'
             '● Quà chào mừng và không gian làm việc, văn phòng hoàn toàn mới, '
             'hiện đại, tiện nghi với tầm nhìn đẹp.\n'
             '● Cơ hội phát triển & nâng cao mạng lưới kết nối một cách chuyên '
             'nghiệp & rộng lớn.\n'
             '● Hướng dẫn tận tình, đồng nghiệp thân thiện quan tâm giúp đỡ '
             'nhau.\n'
             '● Được trải nghiệm công việc thật, tích luỹ kinh nghiệm.\n'
             '● Có thể được xem xét làm nhân viên chính thức.\n'
             '● Gửi xe miễn phí.',
 'company': 'CÔNG TY TNHH DAOUKIWOOM INNOVATION',
 'deadline': '',
 'description': '● Nhận danh sách các vị trí cần tuyển dụng từ Leader.\n'
                '● Đăng tin tuyển dụng trên các tất cả các kênh tuyển dụng, '
                'mạng xã hội để tiếp cận và thu hút ứng viên.\n'
                '● Trao đổi và giải đáp thắc mắc của Ứng viên về vị trí và yêu '
                'cầu tuyển dụng (nếu có).\n'
                '● Tìm kiếm các kênh đăng tuyển dụng mới.\n'
                '● Báo cáo định kỳ cho Leader và đề xuất các phương án để '
                'tuyển dụng hiệu quả.\n'
                '● Các công việc khác theo sự trao đổi từ Leader.',
 'experience': 'Không yêu cầu kinh nghiệm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/it-recruitment-intern/1406078.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Trên 1.2 triệu',
 'title': 'IT Recruitment Intern'}
2024-07-16 19:33:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/senior-lead-embedded-test/1397329.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:33:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/senior-lead-embedded-test/1397329.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty TNHH Kaii Soft',
 'deadline': '',
 'description': 'Kaii Soft company is looking for embedded test with the '
                'passion and ability to grow together.\n'
                'Currently, we need excellent engineers who can work with '
                'Korea company to perform embedded software testing and '
                'verification for the ISO26262 standard for application to '
                'autonomous vehicles. \n'
                'If you are passionate about the embedded systems field and '
                'enjoy continuous learning and development, apply now!',
 'experience': '3 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/senior-lead-embedded-test/1397329.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Senior/Lead Embedded Test'}
2024-07-16 19:33:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/lap-trinh-vien-java-springboot-tai-ha-noi-thu-nhap-upto-40-trieu-thang-tu-3-nam-kinh-nghiem/1398031.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:33:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/lap-trinh-vien-java-springboot-tai-ha-noi-thu-nhap-upto-40-trieu-thang-tu-3-nam-kinh-nghiem/1398031.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty cổ phần Công nghệ thông tin Phú Minh',
 'deadline': '',
 'description': '',
 'experience': '3 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/lap-trinh-vien-java-springboot-tai-ha-noi-thu-nhap-upto-40-trieu-thang-tu-3-nam-kinh-nghiem/1398031.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '25 - 40 triệu',
 'title': 'Lập Trình Viên Java (Springboot) - Tại Hà Nội - Thu Nhập Upto 40 '
          'Triệu/Tháng - Từ 3 Năm Kinh Nghiệm'}
2024-07-16 19:33:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/data-engineer-middle-senior/1358441.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:33:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/data-engineer-middle-senior/1358441.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Viettel Software',
 'deadline': '',
 'description': '',
 'experience': '5 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/data-engineer-middle-senior/1358441.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '30 - 50 triệu',
 'title': 'Data Engineer (Middle/Senior)'}
2024-07-16 19:33:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/video-editor/1389288.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:33:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/video-editor/1389288.html?ta_source=ITJobs_LinkDetail>
{'benefits': '- Thưởng: thưởng các ngày lễ, Tết; thưởng kết quả công việc; '
             'thưởng đột xuất khác\n'
             '- Xét tăng lương 1-2 lần trong năm\n'
             '- Phụ cấp: phụ cấp ăn trưa, điện thoại, đi lại; phụ cấp trách '
             'nhiệm\n'
             '- Phúc lợi xã hội: bảo hiểm xã hội, bảo hiểm y tế, bảo hiểm thất '
             'nghiệp\n'
             '- Chế độ nghỉ phép, nghỉ ngày lễ theo quy định của Nhà nước\n'
             '- Chế độ nghỉ mát hàng năm, teambuilding hàng tháng, quý\n'
             '- Chế độ thai sản\n'
             '- Khám sức khỏe định kỳ hàng năm\n'
             '- Thăm hỏi, động viên, giúp đỡ tinh thần và vật chất cho nhân '
             'viên: cưới hỏi, bệnh tật, tai nạn, việc hiếu\n'
             '- Tặng quà các cháu thiếu nhi dịp Quốc tế thiếu nhi, tết Trung '
             'thu\n'
             '- Tổ chức, khuyến khích các hoạt động thể thao tăng cường sức '
             'khỏe và tình đoàn kết\n'
             '- Chúc mừng sinh nhật nhân viên hàng tháng\n'
             '- Liên hoan, picnic, team building định kỳ',
 'company': 'Công ty TNHH Đầu Tư và Phát Triển Phần Mềm Bắc Hà',
 'deadline': '',
 'description': '• Lên ý tưởng và làm video quảng cáo App/Web\n'
                '• Cắt ghép các video giới thiệu app, các video phục vụ cho '
                'Marketing truyền thông của công ty\n'
                '• Các công việc khác được Leader phân công.',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/video-editor/1389288.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '10 - 20 triệu',
 'title': 'Video Editor'}
2024-07-16 19:33:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/lap-trinh-vien-php/1057431.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:33:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/lap-trinh-vien-php/1057431.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Môi trường làm việc thân thiện, thoải mái\n'
             '- Thu nhập hấp dẫn: Lương cứng 14-18 triệu/tháng + hoa hồng dự '
             'án. \n'
             '- Thưởng tháng, quý, năm và các ngày Lễ Tết theo quy định của '
             'Công ty\n'
             '- Đóng BHXH sau thời gian thử việc và bảo hiểm chăm sóc sức khỏe '
             'dành riêng cho cấp quản lý\n'
             '- Du lịch hàng năm cùng Công ty, tham gia team building...\n'
             '- Các chế độ khác: Theo Luật Lao động, theo Nội quy lao động và '
             'Quy định tài chính của công ty.',
 'company': 'Công ty TNHH Đầu tư và công nghệ Hoàng Vũ',
 'deadline': '',
 'description': '- Phát triển hệ thống website bằng ngôn ngữ PHP '
                'CodeIgniter/Laravel phục vụ các giải pháp: Phần mềm quản lý '
                'giáo dục, quản lý hệ thống học tập trực tuyến, CRM. \n'
                '- Nghiên cứu và áp dụng công nghệ mới phù hợp với định hướng '
                'và chiến lược phát triển của dự án, công ty.',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/lap-trinh-vien-php/1057431.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '12 - 25 triệu',
 'title': 'Lập Trình Viên PHP'}
2024-07-16 19:33:34 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 11 pages/min), scraped 10 items (at 10 items/min)
2024-07-16 19:33:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/data-engineer-big-data/156406.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:33:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/data-engineer-big-data/156406.html?ta_source=ITJobs_LinkDetail>
{'benefits': '- Thu nhập cao tương xứng với trình độ. Lên tới '
             '50.000.000/Tháng\n'
             '- Môi trường làm việc trẻ trung, năng động\n'
             '\n'
             '- Tham dự các dự án lớn, ứng dụng các công nghệ hàng đầu\n'
             '\n'
             '- Tham dự hội thảo chuyên ngành trên toàn thế giới\n'
             '\n'
             '- Lộ trình thăng tiến và phát triển sự nghiệp\n'
             '\n'
             '- Thu nhập hấp dẫn tùy theo năng lực của từng cá nhân\n'
             '\n'
             '- Chế độ nghỉ mát và khám sức khỏe, đóng BHXH theo quy định của '
             'Luật lao động.',
 'company': 'Khối Công nghệ thông tin - Viettel Telecom',
 'deadline': '',
 'description': '- Xây dựng, phát triển các hệ thống lưu trữ, xử lý dữ liệu '
                'lớn (Big Data)\n'
                '- Xây dựng các giải pháp ETL có khả năng mở rộng linh hoạt '
                'với độ tin cậy cao, phục vụ cho việc khai thác/ ingest các '
                'loại dữ liệu (cấu trúc, lưu lượng, tốc độ) từ nhiều nguồn '
                'khác nhau\n'
                '\n'
                '- Xây dựng, phát triển các công cụ khai thác dữ liệu, quản '
                'trị dữ liệu\n'
                '\n'
                '- Thiết kế chi tiết giải pháp cho các luồng thu thập, chuẩn '
                'hóa, làm sạch, làm giàu, lưu trữ, xử lý, phân tích và hiển '
                'thị dữ liệu lớn\n'
                '- Phối hợp, hỗ trợ Data Scientist trong việc chuyển đổi các '
                'mô hình, thuật toán học máy, khai phá dữ liệu thành các bản '
                'đặc tả, thiết kế phần mềm đảm bảo chúng có thể được cài đặt, '
                'triển khai hiệu quả trên môi trường tính toán phân tán và có '
                'khả năng mở rộng tốt khi tập dữ liệu đầu vào tăng trưởng '
                'nhanh\n'
                '\n'
                '- Thiết kế giải pháp và trực tiếp phát triển các module, thư '
                'viện có tính chất nền tảng, có khả năng tái sử dụng cao, ảnh '
                'hưởng diện rộng',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/data-engineer-big-data/156406.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '- Tốt nghiệp ĐH chính quy loại khá trở lên chuyên ngành khoa '
                 'học dữ liệu, khoa học máy tính, CNTT, toán học ứng dụng, '
                 'điện tử viễn thông hoặc liên quan',
 'salary': 'Thoả thuận',
 'title': 'Data Engineer (Big Data)'}
2024-07-16 19:33:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/fresher-tester-ha-noi-ho-chi-minh/1405104.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:33:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/fresher-tester-ha-noi-ho-chi-minh/1405104.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'BSS Group',
 'deadline': '',
 'description': '',
 'experience': 'Dưới 1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/fresher-tester-ha-noi-ho-chi-minh/1405104.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội, Hồ Chí Minh',
 'requirements': '',
 'salary': '7 - 14 triệu',
 'title': 'Fresher Tester (Hà Nội, Hồ Chí Minh)'}
2024-07-16 19:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/it-business-development-sales/1349675.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:33:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/it-business-development-sales/1349675.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY TNHH ISB VIỆT NAM',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/it-business-development-sales/1349675.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'IT Business Development ( Sales )'}
2024-07-16 19:33:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/nhan-vien-kinh-doanh-phan-mem-chi-tuyen-nam-tai-35-le-van-thiem-ha-noi-thu-nhap-tu-20-trieu-di-lam-ngay/904421.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:33:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/nhan-vien-kinh-doanh-phan-mem-chi-tuyen-nam-tai-35-le-van-thiem-ha-noi-thu-nhap-tu-20-trieu-di-lam-ngay/904421.html?ta_source=ITJobs_LinkDetail>
{'benefits': '- Được đóng BH theo quy định của luật lao động\n'
             '- Được khám sức khỏe định kỳ tại bệnh viện đa khoa Quốc tế. Được '
             'hỗ trợ 50 -100% chi phí sau bảo hiểm nếu không may phải nằm '
             'viện\n'
             '- Được làm việc trong môi trường phần mềm Marketing top đầu tại '
             'Việt Nam.\n'
             '- Được học và làm việc tại môi trường công nghệ, giúp bạn luôn '
             'Update và hoàn thiện bản thân.\n'
             '- Được thể hiện đam mê, thoải mái diễn, thể hiện bản thân vì đất '
             'rất rộng, cơ hội thăng tiến và thu nhập không giới hạn.\n'
             '- Được thoải mái chửi, mắng Sếp, nếu Sếp không làm những gì Sếp '
             'đã nói.\n'
             '- Được đào tạo nội bộ, được học từ những chuyên gia Công ty mời '
             'về định kỳ mỗi tháng.\n'
             '- Được tụ tập hát hò tiệc ngọt ít nhất 1 lần/ tháng và du lịch, '
             'thưởng tháng lương tháng 13.\n'
             '- Được rèn luyện học tập và làm việc trong môi trường toàn Đại '
             'Bàng.\n'
             '- Được sử dụng các phần mềm Marketing, được đào tạo để trở thành '
             'chiến binh Digital Marketing.\n'
             '- Được có 1 công việc ổn định, lộ trình thăng tiến và phát triển '
             'rõ ràng.\n'
             '- Bạn sẽ là chuyên gia về phần mềm Marketing và chuyên gia '
             'Digital Marketing sau 1 năm.\n'
             '- Bạn sẽ là người dám thay đổi vận mệnh nếu làm tại MKT.\n'
             'Văn hóa của chúng tôi:\n'
             '\n'
             '- Văn hóa chào cờ sáng thứ 2: Văn hóa chào cờ thứ 2, là nét đẹp '
             'về uống nước nhớ nguồn, kết nối thành viên MKT như 1 ngôi nhà '
             'thứ 2. Là hoạt động có ý nghĩa vô cùng to lớn, khơi nguồn năng '
             'lượng cho 1 tuần làm việc đầy sức mạnh và tích cực.\n'
             '\n'
             '- Văn hóa biết ơn: Vì sao phải biết ơn?\n'
             '\n'
             '+ Vì biết ơn là cuội nguồn của sức mạnh, là truyền thống uống '
             'nước nhớ nguồn của người Việt Nam. Và chúng ta là người Việt '
             'Nam\n'
             '\n'
             '+ Vì không ai muốn giúp, cộng tác, làm việc, sống cùng và hợp '
             'tác với người vô ơn.\n'
             '\n'
             '+ Vì BIẾT ƠN là giá trị cốt lõi của công ty.\n'
             '\n'
             '- Văn hóa cười: "Gặp nhau là phải cười – Chào nhau bằng nụ '
             'cười"\n'
             '\n'
             '- Tại MKT Con người phù hợp là quan trọng nhất.\n'
             '\n'
             '- Chúng tôi Chọn tập thể, không chọn cá nhân.',
 'company': 'Công ty cổ phần giải pháp MKT',
 'deadline': '',
 'description': '',
 'experience': 'Dưới 1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/nhan-vien-kinh-doanh-phan-mem-chi-tuyen-nam-tai-35-le-van-thiem-ha-noi-thu-nhap-tu-20-trieu-di-lam-ngay/904421.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '- Giới tính: Nam',
 'salary': 'Trên 20 triệu',
 'title': 'Nhân Viên Kinh Doanh Phần Mềm (Chỉ Tuyển Nam) Tại 35 Lê Văn Thiêm, '
          'Hà Nội - Thu Nhập Từ 20 Triệu - Đi Làm Ngay'}
2024-07-16 19:33:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:33:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/digital-marketing-lead-generation/1366012.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:33:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/digital-marketing-lead-generation/1366012.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY TNHH ISB VIỆT NAM',
 'deadline': '',
 'description': '• Craft and implement comprehensive digital marketing '
                'campaigns across various platforms, including social media '
                '(Facebook, Google, LinkedIn, etc.). Continuously monitor and '
                'measure performance against established goals (ROI and KPIs). '
                'Leverage data insights to identify areas for improvement and '
                'make data-driven adjustments to optimize campaigns.\n'
                '• Take ownership of consistent growth and performance '
                'improvements across all marketing channels, optimizing '
                'strategies for maximum impact. Benchmark competitor campaigns '
                'and market trends to gain valuable insights and identify '
                'opportunities for innovation and strategic improvement.\n'
                '• Design and manage the lead qualification funnel (MQL to '
                'SAL), nurturing leads and ensuring a seamless handover to the '
                'sales team.\n'
                '• Stay abreast of the latest digital marketing trends and '
                'technologies, actively researching new solutions to enhance '
                'campaign effectiveness.',
 'experience': '3 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/digital-marketing-lead-generation/1366012.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': '15 - 30 triệu',
 'title': 'Digital Marketing ( Lead Generation )'}
2024-07-16 19:34:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/senior-lead-embedded-engineer-c-linux/1397319.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:34:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/senior-lead-embedded-engineer-c-linux/1397319.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty TNHH Kaii Soft',
 'deadline': '',
 'description': 'Kaii Soft company is looking for embedded software engineers '
                'with the passion and ability to grow together.\n'
                'Currently, we need excellent engineers capable of developing '
                'embedded S/W for application to self-driving cars in '
                'cooperation with Korea company.\n'
                'If you are passionate about the embedded systems field and '
                'enjoy continuous learning and development, apply now\n'
                'You will be responsible for:',
 'experience': 'Trên 5 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/senior-lead-embedded-engineer-c-linux/1397319.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Senior/Lead Embedded Engineer (C++/Linux)'}
2024-07-16 19:34:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/senior-business-analyst-tech-department/1391530.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:34:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/senior-business-analyst-tech-department/1391530.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY TNHH DIGI-TEXX',
 'deadline': '',
 'description': 'The senior Business Analyst (BA) plays a vital role to link '
                'between the company, teams, and clients. This role works on '
                'projects inside and outside the company to get important '
                'results. The main job is to understand what everyone needs, '
                'analyze it, and come up with solutions. After giving out '
                'solutions, the senior BA works closely with the Development '
                'team, Testing team, and others to ensure everything is '
                'implemented successfully. The senior BA also shares the '
                'findings and suggestions with the teams and clients.',
 'experience': '5 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/senior-business-analyst-tech-department/1391530.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Senior Business Analyst (Tech Department)'}
2024-07-16 19:34:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/junior-vuejs-developer-lap-trinh-vien-vuejs/944887.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:34:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/junior-vuejs-developer-lap-trinh-vien-vuejs/944887.html?ta_source=ITJobs_LinkDetail>
{'benefits': '1. Chế độ lương, thưởng, thu nhập:\n'
             '2. Môi trường làm việc\n'
             '3. Cơ hội phát triển bản thân\n'
             '4.Địa điểm làm việc',
 'company': 'Viettel Software',
 'deadline': '',
 'description': '',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/junior-vuejs-developer-lap-trinh-vien-vuejs/944887.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '10 - 18 triệu',
 'title': 'Junior Vuejs Developer (Lập Trình Viên Vuejs)'}
2024-07-16 19:34:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/it-support-engineer-microsoft-crm-erp-software/654470.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:34:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/it-support-engineer-microsoft-crm-erp-software/654470.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Tek Experts sẽ offer bạn job FULL TIME với mức lương HẤP DẪN, '
             'cùng với:\n'
             '1. Lương, thưởng, bảo hiểm:\n'
             '- Được nhận 100% lương trong thời gian On Job Training\n'
             '- Được đóng bảo hiểm trên 100% lương\n'
             '- Được nhận Performance bonus/KPI bonus hàng quý và cuối năm\n'
             '- Bảo hiểm sức khỏe PTI (hiện tại điều trị ngoại trú lên tới 15 '
             'triệu/năm, nội trú lên tới 100 triệu/năm)\n'
             '- Được health check 1 năm/lần tại các bệnh viện lớn\n'
             '2. Training & development:\n'
             '- Được native English instructor (từng giảng dạy tại British '
             'University Vietnam, ĐH Hà Nội, ĐH Quốc Gia HN, Language Link '
             'Vietnam...) song hành giảng dạy\n'
             '- Được tham gia rất nhiều khóa đào tạo kĩ năng mềm bổ ích: '
             'Cultivate Your Leadership Program, Unleash Your Potential '
             'Program...\n'
             '- Có cơ hội được offer cross-business-line, internal '
             'transfer/promotion\n'
             '3. Internal activities:\n'
             '- Được tham gia cực nhiều hoạt động nội bộ thú vị: Ngày hội Book '
             'Exchange, Tek Experts Uprace - Run for Community, Tek Expert '
             'Summer Trip, Giải bóng đá Tek League, Tek Experts Table Tennis '
             'Tournament, Loyal Employee Ceremony, Tek Experts X-Factor, Year '
             'End party,...\n'
             '- Được nhận quà vào các dịp lễ hàng năm từ công đoàn\n'
             '4. Working environment:\n'
             '- Làm việc 100% với khách hàng nước ngoài, giao tiếp hoàn toàn '
             'bằng tiếng Anh\n'
             '- Đồng nghiệp trẻ trung từ nhiều quốc gia khác nhau, trải nghiệm '
             'môi trường đa văn hóa đúng nghĩa\n'
             '- Văn phòng tọa lạc tại Lotte Centre, toà nhà cao thứ 3 tại Việt '
             'Nam với khu 360-panorama city view, pantry Sky Garden với bàn bi '
             'lắc và bóng bàn\n'
             '- Được trang bị những thiết bị làm việc tối tân với 2 màn hình '
             'máy tính',
 'company': 'Tek Experts Vietnam',
 'deadline': '',
 'description': 'Tek Experts là sự kết hợp hoàn hảo giữa con người và công '
                'nghệ. Tek Experts cung cấp dịch vụ IT Outsourcing đồng thời '
                'hỗ trợ các tập đoàn trên thế giới trong các khâu thiết yếu '
                'của hoạt động kinh doanh.\n'
                'Là đối tác chính thức của Microsoft tại Việt Nam, Tek Experts '
                'đang tìm kiếm Technical Support Engineer - Kỹ sư Hỗ trợ Phần '
                'mềm cho các sản phẩm Microsoft Dynamics.\n'
                'Tại vị trí này, bạn sẽ đóng vai trò:\n'
                '- Là đầu mối kỹ thuật chính, cung cấp các giải pháp hỗ trợ '
                'các khách hàng doanh nghiệp và đối tác nước ngoài,\n'
                '- Khắc phục sự cố kỹ thuật liên quan tới các sản phẩm phần '
                'mềm của Microsoft Dynamics CRM (Customer Relationship '
                'Management) và Dynamics ERP (Enterprise Resources Planning).\n'
                '-Bạn sẽ có cơ hội phát triển trong một môi trường có nhịp độ '
                'công việc nhanh và đầy thách thức, nơi mọi người đều được '
                'trao quyền và cam kết mang lại trải nghiệm khách hàng tốt '
                'nhất.\n'
                'Đến với Tek Experts, các bạn sẽ có cơ hội tiếp cận, học hỏi '
                'và làm chủ các công nghệ hàng đầu:\n'
                '• Dynamics CE/CRM\n'
                '• Power App/ Automate\n'
                '• Azure\n'
                '• Office 365\n'
                '• Windows Server\n'
                '• .NET Development\n'
                '• SQL',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/it-support-engineer-microsoft-crm-erp-software/654470.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Trên 600 USD',
 'title': 'IT Support Engineer - Microsoft CRM & ERP Software'}
2024-07-16 19:34:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/nhan-vien-marketing-website-facebook/862883.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:34:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/nhan-vien-marketing-website-facebook/862883.html?ta_source=ITJobs_LinkDetail>
{'benefits': '- Lương: Upto 7-18tr/ tháng. (Thu nhập: Cam kết thu nhập trung '
             'bình từ 8tr trở lên khi làm theo sự hướng dẫn của quản lý trực '
             'tiếp)\n'
             '- Được đào tạo, kĩ năng + kiến thức Dighital Marketing (google '
             'ads, fb ads, zalo ads, content,.....)\n'
             '- Hưởng đầy đủ các chế độ theo quy định của nhà nước (Sau 2 '
             'Tháng Thử việc)\n'
             '- Đặc Biệt \n'
             '- Cơ hội thu nhập cao, thăng tiến theo năng lực của bản thân (Vì '
             'môi trường làm việc starup)\n'
             '- Môi trường thân thiện, năng động làm nhiều thì tiền nhiều, làm '
             'ít thì tiền ít, ngồi chơi thì không có tiền.',
 'company': 'CÔNG TY CỔ PHẦN QUẢN TRỊ THÔNG MINH ASIA',
 'deadline': '',
 'description': '- Tất cả đều được đào tạo trong quá trình làm việc nên các '
                'các bạn cứ yên mà làm nhé.\n'
                '- Liên hệ và tư vấn khách hàng về lĩnh vực Quảng cáo '
                'Marketing Website, Google ADS, Digital, SEO, Hosting và các '
                'dịch vụ liên quan phần mềm công nghệ (đi tư vấn nếu khách '
                'hàng cần gặp trực tiếp ký hợp đồng)\n'
                '- Đàm phán, đưa ra các chiến lược marketing : Facebook ads, '
                'Google ADS, SEO,...\n'
                '- Sau khi ký hợp đồng chuyển qua giai đoạn làm website và '
                'marketing: Viết bài content chăm sóc website. Lên chiến lược '
                'marketing: Facebook ads, Google ADS, SEO \n'
                '- Tối ưu website, xây dựng nội dung, xây dựng liên kết bền '
                'vững.\n'
                '- Cập nhật thường xuyên các thay đổi của Google',
 'experience': 'Không yêu cầu kinh nghiệm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/nhan-vien-marketing-website-facebook/862883.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Nhân Viên Marketing Website - Facebook'}
2024-07-16 19:34:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/business-analyst-ba-phan-tich-nghiep-vu/1399001.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:34:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/business-analyst-ba-phan-tich-nghiep-vu/1399001.html?ta_source=ITJobs_LinkDetail>
{'benefits': '- Thu nhập hấp dẫn tùy theo năng lực của từng cá nhân ( trong '
             'khoảng 10-20 triệu)\n'
             '- Thưởng tháng 13, thưởng theo hiệu quả dự án, Lễ, Tết,...\n'
             '\n'
             '- Cung cấp đầy đủ trang thiết bị khi làm việc- Môi trường làm '
             'việc trẻ trung, năng động\n'
             '- Tham dự các dự án lớn, ứng dụng các công nghệ hàng đầu\n'
             '\n'
             '- Lộ trình thăng tiến và phát triển sự nghiệp\n'
             '\n'
             '- Chế độ nghỉ mát, đóng BHXH theo quy định của Luật lao động.',
 'company': 'CÔNG TY CỔ PHẦN CÔNG NGHỆ SOPEN VIỆT NAM',
 'deadline': '',
 'description': '- Thiết kế các giải pháp kỹ thuật hiệu quả và phân tích các '
                'thông số kỹ thuật của hệ thống để đáp ứng các yêu cầu nghiệp '
                'vụ.\n'
                '\n'
                '- Chủ động giao tiếp và cộng tác với khách hàng bên ngoài và '
                'bên trong để phân tích nhu cầu thông tin và các yêu cầu chức '
                'năng.\n'
                '\n'
                '- Phối hợp với tất cả các bên liên quan để thực hiện phân '
                'tích, nghiên cứu và đưa ra các giải pháp hiệu quả.\n'
                '\n'
                '- Đảm bảo tài liệu rõ ràng và chính xác bao gồm doanh nghiệp '
                'và khách hàng yêu cầu, thông số kỹ thuật và báo cáo.\n'
                '\n'
                '- Hỗ trợ về Kiểm tra sự chấp nhận của người dùng chứng minh '
                'rằng các mong muốn của khách hàng đã được đáp ứng.\n'
                '\n'
                '- Xác định mục tiêu hoạt động bằng cách nghiên cứu các chức '
                'năng nghiệp vụ; thu thập thông tin; đánh giá các yêu cầu và '
                'định dạng đầu ra.\n'
                '\n'
                '- Cung cấp tài liệu tham khảo cho người dùng bằng cách viết '
                'và duy trì tài liệu người dùng; tài liệu hướng dẫn; đào tạo '
                'người dùng.\n'
                '\n'
                '- Hỗ trợ đưa các đề xuất mới cho khách hàng, giúp phân tích '
                'yêu cầu, phân tích nhiệm vụ và quy trình làm việc, định nghĩa '
                'quy trình nghiệp vụ, trường hợp sử dụng, kịch bản, thiết kế '
                'màn hình và giao diện, v.v.\n'
                '\n'
                '- Lập kế hoạch cho giai đoạn yêu cầu khi bắt đầu dự án.\n'
                '\n'
                '- Phân công nhiệm vụ và quản lý các nhóm để đảm bảo rằng dự '
                'án chạy trơn tru\n'
                '\n'
                '- Phân tích luồng nghiệp vụ và yêu cầu của người dùng.\n'
                '\n'
                '- Ghi chép chi tiết các yêu cầu nghiệp vụ của khách hàng.\n'
                '\n'
                '- Tham gia đánh giá đồng nghiệp và kiểm tra các tài liệu yêu '
                'cầu',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/business-analyst-ba-phan-tich-nghiep-vu/1399001.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '10 - 20 triệu',
 'title': 'Business Analyst ( BA ) - Phân Tích Nghiệp Vụ'}
2024-07-16 19:34:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/nhan-vien-phan-tich-nghiep-vu-phan-mem/1406155.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:34:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/nhan-vien-phan-tich-nghiep-vu-phan-mem/1406155.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY CỔ PHẦN CÔNG NGHỆ TRUYỀN THÔNG DTS',
 'deadline': '',
 'description': '',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/nhan-vien-phan-tich-nghiep-vu-phan-mem/1406155.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '10 - 14 triệu',
 'title': 'Nhân Viên Phân Tích Nghiệp Vụ (Phần Mềm)'}
2024-07-16 19:34:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/ky-su-trien-khai-he-thong-mang-va-bao-mat/1388253.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:34:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/ky-su-trien-khai-he-thong-mang-va-bao-mat/1388253.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Cơ hội làm việc trực tiếp với các hãng hàng đầu toàn cầu. Triển '
             'khai nhiều sản phẩm/ giải pháp đa dạng cùng tập khách hàng lớn '
             'và những dự án lớn. Được đồng hành, hỗ trợ bởi các chuyên gia '
             'giàu kinh nghiệm trong nước và quốc tế.\n'
             '- Văn phòng làm việc hiện đại với không gian mở; môi trường trẻ '
             'trung, năng động, sáng tạo và phát triển.\n'
             '- Gói đãi ngộ cạnh tranh với\n'
             ' cùng chính sách nâng lương linh hoạt.\n'
             '- Khám sức khỏe thường niên.\n'
             '- Được hưởng toàn bộ các quyền lợi theo Luật lao động ban hành '
             'về chế độ tham gia bảo hiểm xã hội, nghỉ lễ, nghỉ phép năm. Các '
             'hoạt động văn hóa, giải trí phong phú: Du lịch, teambuilding, '
             'ngày hội sinh nhật công ty tại các địa điểm du lịch, resort cao '
             'cấp.',
 'company': 'Công ty Cổ phần Phúc Thành Việt Nam',
 'deadline': '',
 'description': '- Triển khai cài đặt, cấu hình thiết bị mạng, bảo mật, các '
                'giải pháp mà công ty cung cấp.\n'
                '- Tìm hiểu, nghiên cứu các giải pháp mới.\n'
                'Hỗ trợ kỹ thuật /phối hợp với nhà cung cấp xử lý các trường '
                'hợp hệ thống của khách hàng gặp sự cố.\n'
                'Thực hiện các công việc khác do Trưởng phòng hoặc Lãnh đạo '
                'Công ty phân công.',
 'experience': 'Không yêu cầu kinh nghiệm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/ky-su-trien-khai-he-thong-mang-va-bao-mat/1388253.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Kỹ Sư Triển Khai Hệ Thống Mạng Và Bảo Mật'}
2024-07-16 19:34:34 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 14 pages/min), scraped 23 items (at 13 items/min)
2024-07-16 19:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/ky-su-trien-khai-he-thong-may-chu-va-luu-tru/1010009.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:34:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/ky-su-trien-khai-he-thong-may-chu-va-luu-tru/1010009.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty Cổ phần Phúc Thành Việt Nam',
 'deadline': '',
 'description': '',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/ky-su-trien-khai-he-thong-may-chu-va-luu-tru/1010009.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Tới 25 triệu',
 'title': 'Kỹ Sư Triển Khai Hệ Thống Máy Chủ Và Lưu Trữ'}
2024-07-16 19:34:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/senior-seo-thu-nhap-hap-dan-15-20-trieu-thang/1401502.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=)
2024-07-16 19:34:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/senior-seo-thu-nhap-hap-dan-15-20-trieu-thang/1401502.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty TNHH TM & Truyền Thông Vũ Long',
 'deadline': '',
 'description': '',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/senior-seo-thu-nhap-hap-dan-15-20-trieu-thang/1401502.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': '15 - 20 triệu',
 'title': 'Senior SEO - Thu Nhập Hấp Dẫn 15- 20 Triệu / Tháng'}
2024-07-16 19:34:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/nhan-vien-kiem-thu-tester/1223161.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:34:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/nhan-vien-kiem-thu-tester/1223161.html?ta_source=ITJobs_LinkDetail>
{'benefits': '● Mức lương từ 7.000.000 đến 15.000.000 tùy thuộc vào kỹ năng và '
             'kinh nghiệm.\n'
             '● Sản phẩm sáng tạo, công nghệ tiên tiến, hiện đại, liên tục cập '
             'nhật, đáp ứng nhu cầu thị\n'
             'trường.\n'
             '● Có cơ hội thăng tiến hướng Quản lý hoặc Kỹ thuật cấp cao.\n'
             '● Được tham gia phát triển những sản phẩm sáng tạo, được đóng '
             'góp trực tiếp vào sản phẩm và\n'
             'góp phần kiến tạo sản phẩm.\n'
             '● Môi trường làm việc trẻ, thoải mái, tập trung vào phát triển '
             'con người.\n'
             '● Các ngày nghỉ lễ theo quy định nhà nước.\n'
             '● Xét tăng lương theo dựa vào hiệu suất công việc.\n'
             '● Tham gia vào các hoạt động teambuilding hàng năm của công ty.\n'
             '● Lộ trình thăng tiến xây dựng riêng đối với từng nhân viên.',
 'company': 'NorthStudio TTAS., JSC',
 'deadline': '',
 'description': 'NorthStudio là một đội ngũ phát triển trẻ với những con người '
                'trẻ hướng tới mục tiêu tạo ra các sản phẩm công nghệ tiến bộ '
                'và đầy sáng tạo. Với định hướng phát triển tập trung vào con '
                'người, chúng mình tìm kiếm những con người với mong muốn mang '
                'sức trẻ kiến tạo nên sản phẩm mang tính đột phá. Trong suốt '
                'quá trình phát triển, đội ngũ đã tạo nên những sản phẩm công '
                'nghệ đạt được nhiều ghi nhận từ cộng đồng.\n'
                'Trên hành trình kiến tạo và xây dựng đó, chúng mình đang tìm '
                'kiếm 01 Tester có cùng định hướng\n'
                'phát triển và mong muốn xây dựng nên những sản phẩm cống hiến '
                'cho cộng đồng và xã hội. Cùng với định hướng phát triển thiên '
                'về con người, mong muốn rằng đội ngũ có thể phát triển cùng '
                'nhau để tạo thành một nhóm phát triển đầy triển vọng.\n'
                'Nếu bạn đang tìm cho mình một môi trường trân trọng sự nỗ '
                'lực, ưu tiên sự cống hiến và ghi nhận sự sáng tạo, đây là nơi '
                'mà bạn cần tìm.\n'
                'Thông tin công việc: \n'
                '●Tham gia vào quá trình kiểm thử phần mềm, đảm bảo chất lượng '
                'và đáp ứng yêu cầu của\n'
                'khách hàng.\n'
                '● Thực hiện việc phân tích yêu cầu, thiết kế test case và '
                'test plan.\n'
                '● Thực hiện kiểm thử theo test case đã thiết kế, ghi nhận và '
                'báo cáo lỗi phát hiện.\n'
                '● Tham gia vào công việc triển khai và kiểm tra hệ thống.\n'
                '● Báo cáo công việc cho quản lý và các bộ phận liên quan\n'
                'Thời gian làm việc: \n'
                '●Thời gian: 8h30 - 12h và từ 13h30 - 17h30\n'
                '● Làm việc từ thứ 2- thứ 7, nghỉ thứ 7 cách tuần.',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/nhan-vien-kiem-thu-tester/1223161.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Nhân Viên Kiểm Thử (Tester)'}
2024-07-16 19:34:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/game-backend-developer-c-c/824099.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:34:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/game-backend-developer-c-c/824099.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty Cổ phần GIHOT',
 'deadline': '',
 'description': '',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/game-backend-developer-c-c/824099.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': '8 - 25 triệu',
 'title': 'Game Backend Developer (C/C++)'}
2024-07-16 19:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/lap-trinh-vien-reactjs/1404836.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:35:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/lap-trinh-vien-reactjs/1404836.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY CỔ PHẦN CÔNG NGHỆ UPBASE',
 'deadline': '',
 'description': '',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/lap-trinh-vien-reactjs/1404836.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '10 - 25 triệu',
 'title': 'Lập Trình Viên ReactJS'}
2024-07-16 19:35:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/java-developer-backend/1370999.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:35:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/java-developer-backend/1370999.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY TNHH CÔNG NGHỆ THÔNG TIN VÀ TRUYỀN THÔNG GTEL',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/java-developer-backend/1370999.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Tới 40 triệu',
 'title': 'Java Developer (Backend)'}
2024-07-16 19:35:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/nhan-vien-ho-tro-san-pham-va-trien-khai-phan-mem/1405639.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:35:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/nhan-vien-ho-tro-san-pham-va-trien-khai-phan-mem/1405639.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY CỔ PHẦN INTELNET',
 'deadline': '',
 'description': '',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/nhan-vien-ho-tro-san-pham-va-trien-khai-phan-mem/1405639.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Nhân Viên Hỗ Trợ Sản Phẩm Và Triển Khai Phần Mềm'}
2024-07-16 19:35:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=> (referer: None)
2024-07-16 19:35:15 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://www.topcv.vn/viec-lam/ky-su-trien-khai-he-thong-may-chu-va-luu-tru/1010009.html?ta_source=ITJobs_LinkDetail> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2024-07-16 19:35:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/nhan-vien-ky-thuat-trien-khai-it/1361184.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:35:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/nhan-vien-ky-thuat-trien-khai-it/1361184.html?ta_source=ITJobs_LinkDetail>
{'benefits': '• Thu nhập: Cạnh tranh tùy theo năng lực từ 10.000.000 đến '
             '15.000.000 bao gồm lương năng xuất và có thưởng\n'
             '• Được xét tăng lương định kỳ 1 năm 1 lần theo năng lực \n'
             '• Được đào tạo kỹ năng, chuyên môn từ CƠ BẢN đến NÂNG CAO\n'
             '• Thời gian ký hợp đồng chính thức ngay sau 1 tháng đầu tiên nếu '
             'thực hiện tốt công việc và hưởng 12 ngày phép năm\n'
             '• Công thức lương rõ ràng, đảm bảo tương xứng với hiệu quả công '
             'việc\n'
             '• Được đóng đầy đủ BHYT, BHXH, BHTN theo quy định pháp luật\n'
             '• Được hưởng các chương trình phúc lợi nội bộ của công ty\n'
             '• Môi trường làm việc thân thiện, chuyên nghiệp, năng động và lộ '
             'trình thăng tiến rõ ràng',
 'company': 'CÔNG TY TNHH THƯƠNG MẠI - DỊCH VỤ VÀ PHÁT TRIỂN THỊ TRƯỜNG TÂN '
            'PHÁT',
 'deadline': '',
 'description': '• Triển khai, lắp đặt các thiết bị máy barcode, máy tính máy '
                'văn phòng do Tân Phát cung cấp cho khách hàng \n'
                '• Cài đặt và hướng dẫn khách hàng sử dụng sản phẩm\n'
                '• Hỗ trợ khách hàng online hoặc trực tiếp\n'
                '• Quay video HDSD sản phẩm, đánh giá sản phẩm nhằm giúp khách '
                'hàng hiểu hơn về Sp\n'
                '• Ghi nhận phản hồi trực tiếp từ khách hàng, phối hợp với các '
                'bộ phận liên quan trong việc nâng cao chất lượng dịch vụ của '
                'công ty',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/nhan-vien-ky-thuat-trien-khai-it/1361184.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh, Hà Nội',
 'requirements': '',
 'salary': '10 - 15 triệu',
 'title': 'Nhân Viên Kỹ Thuật Triển Khai IT'}
2024-07-16 19:35:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/sales-admin/1405307.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:35:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/sales-admin/1405307.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'WATA SOFTWARE',
 'deadline': '',
 'description': '',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/sales-admin/1405307.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Sales Admin'}
2024-07-16 19:35:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/lap-trinh-vien-ios/861234.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:35:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/lap-trinh-vien-ios/861234.html?ta_source=ITJobs_LinkDetail>
{'benefits': '- Mức lương 10-35tr\n'
             '- Thưởng các ngày nghỉ lễ , Thưởng lương tháng 13; Thưởng tết: '
             '(2- 5tháng cơ bản tùy năng lực), thưởng dự án, thưởng ý tưởng '
             'hay\n'
             '- Thử việc 100% lương\n'
             '- Phụ cấp ăn trưa, đi lại và nhà trọ\n'
             '- Có cơ hội thăng tiến làm leader ( được hưởng các quyền lợi '
             'thêm)\n'
             '- Review lương 2 lần/năm;\n'
             '- Văn hóa công ty: đọc sách, tập thể dục hàng ngày;\n'
             '- Làm việc trong môi trường trẻ trung, thân thiện và được học '
             'thêm nhiều kinh nghiệm;\n'
             '- Trang bị thiết bị hiện đại, laptop, màn hình lớn;\n'
             '- Chế độ BHXH, BHYT, BHTN theo luật lao động;\n'
             '- Đồ ăn: bánh kẹo, hoa quả/đồ uống miễn phí;\n'
             '- Du lịch hàng năm, tham gia liên hoan hàng tháng;\n'
             '- Tham gia vào CLB Bóng đá của công ty hàng tuần.\n'
             '- Quyền lợi dành cho thành viên làm >1 năm: Khám sức khỏe tổng '
             'quát 1 năm/lần, Cấp vốn mua nhà,mua xe, thẻ tập gym, yoga\n'
             '- Làm việc từ thứ 2 đến thứ 6, nghỉ thứ 7 và CN',
 'company': 'XGame',
 'deadline': '',
 'description': '- Xây dựng và phát triển các ứng dụng trên nền tảng IOS\n'
                '- Cùng team lên ý tưởng và giải pháp cho các tính năng mới '
                'của ứng dụng\n'
                '- Sửa lỗi và cải thiện tính năng, hiệu suất sản phẩm\n'
                '- Phối hợp với các thành viên trong team để vận hành và tối '
                'ưu hoá sản phẩm\n'
                '- Nghiên cứu công nghệ mới, phù hợp với chiến lược sản phẩm\n'
                '- Phối hợp với bên UI/UX để làm ứng dụng trở lên hấp dẫn và '
                'trực quan khi sử dụng\n'
                '- Chi tiết công việc sẽ trao đổi thêm khi phỏng vấn',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/lap-trinh-vien-ios/861234.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Tới 1,500 USD',
 'title': 'Lập Trình Viên IOS'}
2024-07-16 19:35:34 [scrapy.extensions.logstats] INFO: Crawled 36 pages (at 11 pages/min), scraped 33 items (at 10 items/min)
2024-07-16 19:35:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/java-developer/1405737.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:35:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/java-developer/1405737.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty TNHH AEGONA',
 'deadline': '',
 'description': 'Looking for an exciting Java Spring Boot development '
                'opportunity? Join our team and work on innovative projects, '
                'including \n'
                ' and \n'
                '. Leverage your expertise to drive success – explore this '
                'opportunity now!',
 'experience': '3 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/java-developer/1405737.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Java Developer'}
2024-07-16 19:35:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/java-design-lead/1405976.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:35:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/java-design-lead/1405976.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Discover some of the global benefits that empower our people to '
             'become the best version of themselves:',
 'company': 'CÔNG TY TNHH ENDAVA',
 'deadline': '',
 'description': 'Development is the largest discipline at Endava. Our '
                'developers design, build, and release software products in '
                'multiple programming languages, frameworks, and libraries. '
                'Always collaborating with cross-functional project teams, our '
                'developers are adaptable problem-solvers with a '
                'client-oriented mindset. \n'
                'As a Design Lead (Java) at Endava, you are responsible for '
                'developing highly quality software components to deliver '
                "value to stakeholders. You'll handle specifying and designing "
                'complex software application by following design standards '
                "and principles. You'll play a crucial role to designing "
                'systems components and architectures.',
 'experience': 'Trên 5 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/java-design-lead/1405976.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Java Design Lead'}
2024-07-16 19:35:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/account-manager/1405708.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:35:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/account-manager/1405708.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Working time: Monday till Friday (8 AM - 5 PM)',
 'company': 'CÔNG TY TNHH KIMEI GLOBAL',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/account-manager/1405708.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Account Manager'}
2024-07-16 19:35:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/user-acquisition-game/1370207.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:35:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/user-acquisition-game/1370207.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Mức lương có thể thỏa thuận dựa trên năng lực và kinh nghiệm của '
             'bạn, chúng tôi cam kết không bao giờ trả lương thấp hơn khả năng '
             'của bạn. (8-15M)',
 'company': 'WAYFU STUDIO',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/user-acquisition-game/1370207.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'User Acquisition Game'}
2024-07-16 19:35:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/senior-reactjs/1405083.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:35:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/senior-reactjs/1405083.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY CỔ PHẦN ADAMO SOFTWARE',
 'deadline': '',
 'description': '',
 'experience': 'Không yêu cầu kinh nghiệm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/senior-reactjs/1405083.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '25 - 30 triệu',
 'title': 'Senior ReactJS'}
2024-07-16 19:36:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/junior-unity-developer/1370161.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:36:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/junior-unity-developer/1370161.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Mức lương có thể thỏa thuận dựa trên năng lực và kinh nghiệm của '
             'bạn, chúng tôi cam kết không bao giờ trả lương thấp hơn khả năng '
             'của bạn.',
 'company': 'WAYFU STUDIO',
 'deadline': '',
 'description': '',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/junior-unity-developer/1370161.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Junior Unity Developer'}
2024-07-16 19:36:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/automation-tester/1405573.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:36:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/automation-tester/1405573.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Why AMARIS?',
 'company': 'CÔNG TY TNHH AMARIS VIỆT NAM',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/automation-tester/1405573.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Automation Tester'}
2024-07-16 19:36:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/lap-trinh-web-php/1405929.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:36:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/lap-trinh-web-php/1405929.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Xem xét điều chỉnh lương khi cần thiết trong quá trình làm việc '
             'hoặc khi có thành tích vượt trội (không giới hạn số lần tăng '
             'lương trong năm). Các tiêu chí xét điều chỉnh lương:',
 'company': 'Công Ty Cổ Phần VCCorp',
 'deadline': '',
 'description': '',
 'experience': '3 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/lap-trinh-web-php/1405929.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '20 - 25 triệu',
 'title': 'Lập Trình Web (PHP)'}
2024-07-16 19:36:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/product-owner/1406173.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:36:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/product-owner/1406173.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công Ty Cổ Phần Công Nghệ SellerSmith',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/product-owner/1406173.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '1,200 - 1,800 USD',
 'title': 'Product Owner'}
2024-07-16 19:36:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/sales-executive-b2b/1404680.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:36:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/sales-executive-b2b/1404680.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY CỔ PHẦN INTELNET',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/sales-executive-b2b/1404680.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Trên 10 triệu',
 'title': 'Sales Executive B2B'}
2024-07-16 19:36:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/lap-trinh-ios-developer/1404962.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:36:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/lap-trinh-ios-developer/1404962.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Gia nhập FPT, bạn sẽ được làm việc tại một trong những môi '
             'trường làm việc hàng đầu Việt Nam, chúng tôi sẽ mang đến cho '
             'bạn:',
 'company': 'Tập đoàn FPT',
 'deadline': '',
 'description': '',
 'experience': '3 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/lap-trinh-ios-developer/1404962.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '20 - 40 triệu',
 'title': 'Lập Trình IOS Developer'}
2024-07-16 19:36:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/front-end-developer/1195013.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:36:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/front-end-developer/1195013.html?ta_source=ITJobs_LinkDetail>
{'benefits': '- 13th month salary, social insurance\n'
             '- Opportunity to work on new technologies and tools\n'
             '- Opportunity to work with multicultural environment and '
             'travel. \n'
             '- Performance review and adjust salary twice a year \n'
             '- Very attractive remuneration package \n'
             '- A flat hierarchy and a culture of collaboration across all '
             'disciplines\n'
             '- Modern workplace',
 'company': 'Công ty TNHH Phần Mềm Dsoft',
 'deadline': '',
 'description': 'Be responsible for the development and maintenance of Web and '
                'mobile application products, and cooperate with the back-end '
                'to realize the product interface and functions.\n'
                '• Design and develop the Web front-end presentation layer and '
                'the architecture that interacts with the front-end and '
                'back-end.\n'
                '• Develop JavaScript program modules and write general class '
                'libraries and frameworks.\n'
                '• Be responsible for system performance optimization and '
                'tackling technical difficulties.\n'
                '• Be responsible for product feature (requirement) analysis '
                'and understanding, and design the software structure of the '
                'responsible module based on product features, interactive '
                'interface, app software architecture and other information.\n'
                '• According to the software module design, develop the '
                'software module; complete the \n'
                'self-test work of the module and the joint debugging work '
                'between the modules.',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/front-end-developer/1195013.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Front-End Developer'}
2024-07-16 19:36:34 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 12 pages/min), scraped 45 items (at 12 items/min)
2024-07-16 19:36:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/rust-developer/1406045.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:36:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/rust-developer/1406045.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty CP Nghiên cứu và phát triển Fabbi',
 'deadline': '',
 'description': '',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/rust-developer/1406045.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Rust Developer'}
2024-07-16 19:36:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/marketing-manager/1406083.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:36:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/marketing-manager/1406083.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY CỔ PHẦN PHÂN PHỐI NETMARK',
 'deadline': '',
 'description': '',
 'experience': 'Trên 5 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/marketing-manager/1406083.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Marketing Manager'}
2024-07-16 19:36:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/chuyen-vien-kinh-doanh/1406253.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:36:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/chuyen-vien-kinh-doanh/1406253.html?ta_source=ITJobs_LinkDetail>
{'benefits': '- Thu nhập trung bình 200 – 300 triệu/năm\n'
             '\n'
             '- Làm việc trong môi trường chuyên nghiệp, ổn định\n'
             '\n'
             '- Chăm sóc sức khỏe bởi gói Bảo hiểm với quyền lợi lên tới '
             '$8000\n'
             '\n'
             '- Các chế độ bồi dưỡng, phụ cấp ăn trưa, thuê bao nội bộ\n'
             '\n'
             '- Trải nghiệm các hoạt động teambuilding, văn hóa, du lịch, du '
             'xuân, nghỉ mát hè trong và ngoài nước đa dạng...\n'
             '\n'
             '- Thường xuyên tham dự các khóa đào tạo phong phú nhằm giúp '
             'CBCNV không ngừng phát triển bản thân, nâng cao các kỹ năng cũng '
             'như chuyên môn nghề nghiệp',
 'company': 'TRUNG TÂM CNTT MOBIFONE',
 'deadline': '',
 'description': '- Chịu trách nhiệm kinh doanh các sản phẩm, dịch vụ CNTT tới '
                'các khách hàng doanh nghiệp.\n'
                '\n'
                '- Hỗ trợ các chi nhánh của MobiFone tại các tỉnh kinh doanh '
                'giải pháp CNTT.\n'
                '\n'
                '- Xây dựng, quản lý và phát triển đội ngũ cộng tác viên bán '
                'hàng.\n'
                '\n'
                '- Xây dựng, quản lý và phát triển kênh phân phối các giải '
                'phap CNTT.\n'
                '\n'
                '- Nghiên cứu, đề xuất tối ưu quy trình, chính sách kinh '
                'doanh.\n'
                '\n'
                '- Nghiên cứu, đề xuất sản phẩm mới phù hợp với nhu cầu của '
                'thị trường.Chủ trì, phối hợp xây dựng hồ sơ thầu, gói chi phí '
                'để tìm kiếm đối tác, mua sắm sản phẩm/dịch vụ và triển khai '
                'chạy các CTKM/Truyền thông.\n'
                '\n'
                '- Triển khai xây dựng nội dung, kịch bản phục vụ công tác '
                'truyền thông, quảng bá cho các sản phẩm, dịch vụ kinh doanh '
                'trên nền tảng online.',
 'experience': 'Dưới 1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/chuyen-vien-kinh-doanh/1406253.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '15 - 25 triệu',
 'title': 'Chuyên Viên Kinh Doanh'}
2024-07-16 19:36:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/software-support-engineer/1405710.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:36:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/it-business-analyst-chinese/1405762.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:36:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/c-developer-network-linux/1405735.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:37:03 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/analyst-tier-1-soc/1319076.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:37:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/middle-senior-unity-developer/1370172.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:37:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/business-development-executive/1405981.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:37:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/lap-trinh-android-developer/1404904.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:37:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-it-system/1405894.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:37:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/unity-game-developer/1254519.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:37:34 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 3 pages/min), scraped 48 items (at 3 items/min)
2024-07-16 19:37:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3> (failed 1 times): 429 Unknown Status
2024-07-16 19:37:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/qa-manager-it-japanese-n2/1406093.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:37:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-2d-game-artist/603375.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:37:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-2d-animation-game/1406206.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:37:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-lap-trinh-reactjs/1350037.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:37:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/senior-java-full-stack-developer/1406246.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:38:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-kinh-doanh-muc-in-may-in/1403372.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:38:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-kinh-doanh-phan-mem/1380404.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:38:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/junior-middle-ios-swift-developer/1405940.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:38:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/chuyen-vien-designer-nganh-game-app/1368043.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:38:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/senior-js-full-stack/1406075.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:38:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/it-security-phong-cloud-va-ha-tang/1406058.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:38:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/thuc-tap-sinh-flutter-internship-flutter/1340232.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:38:34 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 0 pages/min), scraped 48 items (at 0 items/min)
2024-07-16 19:38:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-ba-tu-1-nam-kinh-nghiem/1367148.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:38:46 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/chuyen-vien-mua-hang-it/811983.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:38:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/junior-senior-flutter-developer/1404715.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:38:51 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/network-system-coordination-and-administration/1341463.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:38:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/lap-trinh-vien-fullstack-nodejs-reactjs-aws/1404287.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:39:01 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/quan-tri-he-thong-system-admin-english-fluent/1404733.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:39:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-it-system/1405894.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:39:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/unity-game-developer/1254519.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:39:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3> (failed 2 times): 429 Unknown Status
2024-07-16 19:39:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/qa-manager-it-japanese-n2/1406093.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:39:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-2d-game-artist/603375.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:39:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-2d-animation-game/1406206.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:39:34 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 0 pages/min), scraped 48 items (at 0 items/min)
2024-07-16 19:39:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-lap-trinh-reactjs/1350037.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:39:40 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/senior-java-full-stack-developer/1406246.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:39:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-kinh-doanh-muc-in-may-in/1403372.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:39:49 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-kinh-doanh-phan-mem/1380404.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:39:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/junior-middle-ios-swift-developer/1405940.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:39:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/chuyen-vien-designer-nganh-game-app/1368043.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:40:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/senior-js-full-stack/1406075.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:40:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/senior-js-full-stack/1406075.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'VĂN PHÒNG ĐẠI DIỆN RICH PAYMENT GROUP CORP TẠI THÀNH PHỐ HỒ CHÍ '
            'MINH',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/senior-js-full-stack/1406075.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Senior JS Full Stack'}
2024-07-16 19:40:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/it-security-phong-cloud-va-ha-tang/1406058.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:40:13 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/thuc-tap-sinh-flutter-internship-flutter/1340232.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:40:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/nhan-vien-ba-tu-1-nam-kinh-nghiem/1367148.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:40:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/nhan-vien-ba-tu-1-nam-kinh-nghiem/1367148.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY CỔ PHẦN TƯ VẤN CÔNG NGHỆ NGS',
 'deadline': '',
 'description': '',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/nhan-vien-ba-tu-1-nam-kinh-nghiem/1367148.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Tới 15 triệu',
 'title': 'Nhân Viên BA Từ 1 Năm Kinh Nghiệm'}
2024-07-16 19:40:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/chuyen-vien-mua-hang-it/811983.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:40:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/junior-senior-flutter-developer/1404715.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:40:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/junior-senior-flutter-developer/1404715.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công Ty Cổ Phần Đầu Tư Và Phát Triển Công Nghệ Proxglobal',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/junior-senior-flutter-developer/1404715.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '15 - 40 triệu',
 'title': 'Junior/Senior Flutter Developer'}
2024-07-16 19:40:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/network-system-coordination-and-administration/1341463.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:40:34 [scrapy.extensions.logstats] INFO: Crawled 54 pages (at 3 pages/min), scraped 51 items (at 3 items/min)
2024-07-16 19:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/quan-tri-he-thong-system-admin-english-fluent/1404733.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:40:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/quan-tri-he-thong-system-admin-english-fluent/1404733.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY CỔ PHẦN AHT TECH',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/quan-tri-he-thong-system-admin-english-fluent/1404733.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Quản Trị Hệ Thống - System Admin (English Fluent)'}
2024-07-16 19:40:42 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/software-support-engineer/1405710.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:40:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/it-business-analyst-chinese/1405762.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:40:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/c-developer-network-linux/1405735.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:40:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/it-business-analyst-chinese/1405762.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'RELIA SYSTEMS',
 'deadline': '',
 'description': '',
 'experience': '3 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/it-business-analyst-chinese/1405762.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'IT Business Analyst (Chinese)'}
2024-07-16 19:40:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/analyst-tier-1-soc/1319076.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:41:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/middle-senior-unity-developer/1370172.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:41:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/middle-senior-unity-developer/1370172.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Mức lương có thể thỏa thuận dựa trên năng lực và kinh nghiệm của '
             'bạn, chúng tôi cam kết không bao giờ trả lương thấp hơn khả năng '
             'của bạn.',
 'company': 'WAYFU STUDIO',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/middle-senior-unity-developer/1370172.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Middle/Senior Unity Developer'}
2024-07-16 19:41:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/business-development-executive/1405981.html?ta_source=ITJobs_LinkDetail> (failed 2 times): 429 Unknown Status
2024-07-16 19:41:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/lap-trinh-android-developer/1404904.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:41:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/lap-trinh-android-developer/1404904.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Gia nhập FPT, bạn sẽ được làm việc tại một trong những môi '
             'trường làm việc hàng đầu Việt Nam, chúng tôi sẽ mang đến cho '
             'bạn:',
 'company': 'Tập đoàn FPT',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/lap-trinh-android-developer/1404904.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Lập Trình Android Developer'}
2024-07-16 19:41:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-it-system/1405894.html?ta_source=ITJobs_LinkDetail> (failed 3 times): 429 Unknown Status
2024-07-16 19:41:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/unity-game-developer/1254519.html?ta_source=ITJobs_LinkDetail> (failed 3 times): 429 Unknown Status
2024-07-16 19:41:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/qa-manager-it-japanese-n2/1406093.html?ta_source=ITJobs_LinkDetail> (failed 3 times): 429 Unknown Status
2024-07-16 19:41:34 [scrapy.extensions.logstats] INFO: Crawled 58 pages (at 4 pages/min), scraped 55 items (at 4 items/min)
2024-07-16 19:41:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-2d-game-artist/603375.html?ta_source=ITJobs_LinkDetail> (failed 3 times): 429 Unknown Status
2024-07-16 19:41:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/nhan-vien-2d-animation-game/1406206.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:41:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/nhan-vien-2d-animation-game/1406206.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty cổ phần Solar Việt Nam',
 'deadline': '',
 'description': '- Thiết kế chuyển động cho các sản phẩm 2D Game\n'
                '- Phối hợp chặt chẽ với các bộ phận liên quan (Designer, '
                'Coder, Artist...) để hoàn thành tốt công việc\n'
                '- Khuyến khích sáng tạo và đưa ra ý tưởng mới trong quá trình '
                'làm việc.\n'
                '- Sử dụng thành thạo Spine , sử dụng được After Effect là 1 '
                'lợi',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/nhan-vien-2d-animation-game/1406206.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '10 - 20 triệu',
 'title': 'Nhân Viên 2D Animation Game'}
2024-07-16 19:41:45 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-lap-trinh-reactjs/1350037.html?ta_source=ITJobs_LinkDetail> (failed 3 times): 429 Unknown Status
2024-07-16 19:41:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:41:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/senior-java-full-stack-developer/1406246.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:41:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/senior-java-full-stack-developer/1406246.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY TNHH AMARIS VIỆT NAM',
 'deadline': '',
 'description': 'ABOUT THE JOB:',
 'experience': '3 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/senior-java-full-stack-developer/1406246.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Senior Java Full Stack Developer'}
2024-07-16 19:41:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-kinh-doanh-muc-in-may-in/1403372.html?ta_source=ITJobs_LinkDetail> (failed 3 times): 429 Unknown Status
2024-07-16 19:42:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/nhan-vien-kinh-doanh-phan-mem/1380404.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:42:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/nhan-vien-kinh-doanh-phan-mem/1380404.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty TNHH Đầu Tư Công Nghệ ST',
 'deadline': '',
 'description': '',
 'experience': 'Dưới 1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/nhan-vien-kinh-doanh-phan-mem/1380404.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': '8 - 15 triệu',
 'title': 'Nhân Viên Kinh Doanh Phần Mềm'}
2024-07-16 19:42:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/junior-middle-ios-swift-developer/1405940.html?ta_source=ITJobs_LinkDetail> (failed 3 times): 429 Unknown Status
2024-07-16 19:42:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/chuyen-vien-designer-nganh-game-app/1368043.html?ta_source=ITJobs_LinkDetail> (failed 3 times): 429 Unknown Status
2024-07-16 19:42:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/it-security-phong-cloud-va-ha-tang/1406058.html?ta_source=ITJobs_LinkDetail> (failed 3 times): 429 Unknown Status
2024-07-16 19:42:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/thuc-tap-sinh-flutter-internship-flutter/1340232.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:42:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/thuc-tap-sinh-flutter-internship-flutter/1340232.html?ta_source=ITJobs_LinkDetail>
{'benefits': '- Được tham gia trải nghiệm thực tế công việc với mức lương phù '
             'hợp trong quá trình đóng góp thực hiện dự án\n'
             '- Được tư vấn định hướng cho chuyên môn sau khi thực tập\n'
             '- Được khả năng ứng tuyển vào vị trí nhân viên chính thức sau '
             'khi ra trường, tốt nghiệp, sau khi thực tập \n'
             '- Cơ hội huấn luyện: Có cơ hội được đào tạo nâng cao kỹ năng '
             'chuyên môn của bản thân và các chuyên ngành khác',
 'company': 'CÔNG TY TNHH STVG',
 'deadline': '',
 'description': '- Phát triển dự án mobile, website, desktop app của Công ty\n'
                '- Cùng tham gia quản lý phân tích và thiết kế các tính năng '
                'sản phẩm\n'
                '- Nghiên cứu công nghệ mới, đưa ra giải pháp áp dụng vào sản '
                'phẩm dịch vụ của công ty\n'
                '- Phối hợp với đồng nghiệp trong nhóm để hoàn thành nhiệm vụ',
 'experience': 'Không yêu cầu kinh nghiệm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/thuc-tap-sinh-flutter-internship-flutter/1340232.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Thực Tập Sinh Flutter (Internship Flutter)'}
2024-07-16 19:42:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/chuyen-vien-mua-hang-it/811983.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:42:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/chuyen-vien-mua-hang-it/811983.html?ta_source=ITJobs_LinkDetail>
{'benefits': '- Môi trường làm việc năng động, thân thiện, chuyên nghiệp với '
             'nhiều cơ hội thăng tiến\n'
             '- Quyền lợi được hưởng\n'
             '- Mức thu nhập: 10.000.000 đ đến 15.000.000đ\n'
             '- Các chế độ BHXH, BHYT, BHTN theo Luật định và theo quy định '
             'công ty.\n'
             '- Thưởng lễ tết theo kết quả kinh doanh năm, theo hiệu quả của '
             'Phòng, theo vị trí đảm nhiệm.\n'
             '- Thưởng lớn theo mục tiêu kết quả kinh doanh quí, năm\n'
             '- Các chế độ phúc lợi thăm hỏi ốm đau, thai sản, sinh nhật, hiếu '
             'hỉ,... theo quy định.\n'
             '- Đánh giá tăng lương định kỳ theo năng lực, cơ hội thăng chức, '
             'tăng lương',
 'company': 'CÔNG TY TNHH THƯƠNG MẠI - DỊCH VỤ VÀ PHÁT TRIỂN THỊ TRƯỜNG TÂN '
            'PHÁT',
 'deadline': '',
 'description': '- Làm việc với các nhà cung cấp có sẵn để mua hàng cho đội '
                'ngũ sale\n'
                '- Đàm phán, thương lượng các điều kiện thương mại với nhà '
                'cung cấp (giá cả, thời gian giao hàng, phương thức thanh '
                'toán...)\n'
                '- Quản lí, đánh giá chất lượng hàng hóa, giá cả và năng lực '
                'của từng nhà cung cấp\n'
                '- Làm việc với các NCC các vấn đề phát sinh về hàng lỗi, hàng '
                'sai số lượng, hỗ trợ bảo hành...\n'
                '- Phối hợp với bộ phận Kho vận để theo dõi tiến độ hàng về.\n'
                '- Các công việc khác theo sự phận công của cấp quản lý.',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/chuyen-vien-mua-hang-it/811983.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '8 - 15 triệu',
 'title': 'Chuyên Viên Mua Hàng IT'}
2024-07-16 19:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/network-system-coordination-and-administration/1341463.html?ta_source=ITJobs_LinkDetail> (failed 3 times): 429 Unknown Status
2024-07-16 19:42:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/software-support-engineer/1405710.html?ta_source=ITJobs_LinkDetail> (failed 3 times): 429 Unknown Status
2024-07-16 19:42:34 [scrapy.extensions.logstats] INFO: Crawled 64 pages (at 6 pages/min), scraped 60 items (at 5 items/min)
2024-07-16 19:42:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/c-developer-network-linux/1405735.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:42:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/c-developer-network-linux/1405735.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'CÔNG TY TNHH ENDAVA',
 'deadline': '',
 'description': 'To develop and maintain a high availability and high-capacity '
                'cluster platform which is used all over the world. It is a '
                'Linux based system with below characteristics: \n'
                'By joining our team, you will have a chance to collaborate '
                'with senior engineers from Australia and other countries to:',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/c-developer-network-linux/1405735.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'C Developer (Network, Linux)'}
2024-07-16 19:42:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/analyst-tier-1-soc/1319076.html?ta_source=ITJobs_LinkDetail> (failed 3 times): 429 Unknown Status
2024-07-16 19:42:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/business-development-executive/1405981.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=2)
2024-07-16 19:42:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/business-development-executive/1405981.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Speed POS',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/business-development-executive/1405981.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hồ Chí Minh',
 'requirements': '',
 'salary': '500 - 900 USD',
 'title': 'Business Development Executive'}
2024-07-16 19:42:53 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-it-system/1405894.html?ta_source=ITJobs_LinkDetail> (failed 4 times): 429 Unknown Status
2024-07-16 19:42:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/unity-game-developer/1254519.html?ta_source=ITJobs_LinkDetail> (failed 4 times): 429 Unknown Status
2024-07-16 19:43:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/it-comtor/1327115.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3)
2024-07-16 19:43:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/it-comtor/1327115.html?ta_source=ITJobs_LinkDetail>
{'benefits': '-Tuần nghỉ 2 ngày, nghỉ lễ, Tết Việt Nam\n'
             '-12 ngày nghỉ phép có lương\n'
             '- \n'
             '- Review lương 1 năm 1 lần và review đột xuất\n'
             '- Lương tháng 13;\n'
             '- Khám sức khỏe định kỳ;\n'
             '- Du lịch hàng năm;\n'
             '- Tiệc giao lưu hàng tháng;\n'
             '- Chỗ gửi xe miễn phí\n'
             '- Văn phòng làm việc không gian mở, rộng rãi, cùng khu pantry '
             'miễn phí\n'
             '- Được các mentor có kinh nghiệm đào tạo và hướng dẫn nhiệt tình',
 'company': 'CÔNG TY TNHH OHMIDAS VIỆT NAM',
 'deadline': '',
 'description': '・Tham gia các buổi meeting với khách hàng Nhật\n'
                '・Phiên dịch cho các buổi họp với Khách hàng Nhật của đội dự '
                'án\n'
                '・Tiếp nhận thông tin từ khách hàng Nhật, phiên dịch lại cho '
                'đội dự án để triển khai công việc\n'
                '・Dịch các loại tài liệu đã tiếp nhận theo yêu cầu, đảm bảo '
                'đúng các nguyên tắc, quy trình dịch thuật của Công ty',
 'experience': '1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/it-comtor/1327115.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '15 - 25 triệu',
 'title': 'IT Comtor'}
2024-07-16 19:43:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/python-back-end-developer-tai-ha-noi-thu-nhap-hap-dan/1306519.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:43:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/back-end-developer-net-c-sql-tai-ha-noi-thu-nhap-hap-dan/1237384.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:43:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/fresher-pre-sales-system-network-security-ha-noi-tuyen-nam-khong-yeu-cau-kinh-nghiem/1405075.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3)
2024-07-16 19:43:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/fresher-pre-sales-system-network-security-ha-noi-tuyen-nam-khong-yeu-cau-kinh-nghiem/1405075.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Chính sách đãi ngộ: \n'
             'Trở thành thành viên AMIGO bạn không chỉ được đảm bảo đầy đủ các '
             'chế độ phúc lợi BHXH, BHYT, BHTN, ngày nghỉ phép, lễ tết đầy đủ '
             'và trọn vẹn mà còn được hưởng chính sách Thu nhập và Đãi ngộ '
             'cạnh tranh trên thị trường, được làm việc trong môi trường '
             'chuyên nghiệp với những đồng nghiệp trẻ trung, nhiệt huyết, luôn '
             'đoàn kết, yêu thương và chia sẻ để mỗi ngày làm việc là một ngày '
             'hạnh phúc vì được cống hiến và phát triển.',
 'company': 'AMIGO',
 'deadline': '',
 'description': '',
 'experience': 'Không yêu cầu kinh nghiệm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/fresher-pre-sales-system-network-security-ha-noi-tuyen-nam-khong-yeu-cau-kinh-nghiem/1405075.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'Fresher Pre-Sales (System/Network & Security) [Hà Nội] - Tuyển Nam, '
          'Không Yêu Cầu Kinh Nghiệm'}
2024-07-16 19:43:23 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/devops/1405062.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:43:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/ios-developer/224475.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3)
2024-07-16 19:43:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/ios-developer/224475.html?ta_source=ITJobs_LinkDetail>
{'benefits': '● Dải lương dự kiến: 8,000,000 – 20,000,000 VNĐ\n'
             '● Thưởng đạt, vượt chỉ tiêu KPI/Thưởng năng suất: Xét thưởng áp '
             'dụng khi nhân viên đạt chỉ tiêu KPI cá nhân và hoặc tùy thuộc '
             'vào tình hình kết quả kinh doanh của công ty.\n'
             '● Thưởng tháng lương 13 (thưởng Tết Âm Lịch): Xét thưởng định kỳ '
             'cuối năm căn cứ theo quy định của công ty và tùy thuộc vào tình '
             'hình kết quả kinh doanh của công ty.\n'
             '● Thưởng thâm niên: Xét thưởng định kỳ cuối năm căn cứ theo thâm '
             'niên làm việc của nhân viên theo quy định của công ty và hoặc '
             'tùy thuộc vào tình hình kết quả kinh doanh của công ty.\n'
             '● Thưởng Nóng, Thưởng thành tích vượt trội: Khi có thành tích '
             'xuất sắc và hoặc dự án thành công...\n'
             '● Thưởng vinh danh, tôn vinh: Bình chọn giải cá nhân/bộ phận '
             'xuất sắc cấp Công ty định kỳ hàng năm\n'
             '● Thưởng Tự Khoe cấp Bộ Phận: Khuyến khích CBNV, các bộ phận thi '
             'đua hoàn thành tốt các mục tiêu công việc, kích thích đổi mới, '
             'sáng tạo trong công việc; ghi nhận, động viên kịp thời các việc '
             'hay, sáng kiến hiệu quả của các các nhân, tập thể. Mức thưởng tự '
             'khoe, tự đề xuất theo quy chế và ngân sách của công ty cấp cho '
             'từng bộ phận.\n'
             'ĐIỀU CHỈNH LƯƠNG: \n'
             'Xem xét điều chỉnh lương khi cần thiết trong quá trình làm việc '
             'hoặc khi có thành tích vượt trội (không giới hạn số lần tăng '
             'lương trong năm). Các tiêu chí xét điều chỉnh lương: \n'
             '• Thời gian làm việc thực tế\n'
             '• Kết quả đánh giá hiệu quả công việc của cá nhân và bộ phận '
             'theo KPI\n'
             '• Năng lực/đóng góp của bản thân\n'
             'CÁC CHẾ ĐỘ PHÚC LỢI:\n'
             'Môi trường và điều kiện làm việc:\n'
             '● Được làm việc trong một công ty game năng động, phát triển, '
             'đứng đầu về mảng mobile game trong thị trường game Việt. Có '
             'nhiều thử thách, có cơ hội được đào tạo và nâng cao nghiệp vụ '
             'thường xuyên.\n'
             '● Làm việc trực tiếp với Ban giám đốc, là những người có kinh '
             'nghiệm, tư duy chiến lược và sáng tạo\n'
             '● Trang thiết bị làm việc công nghệ cao, phong phú, đa dạng.\n'
             '● Văn phòng làm việc hiện đại, chuyên nghiệp, an toàn.\n'
             '● Môi trường trẻ trung, năng động, sáng tạo.\n'
             '● Đồ uống, đồ ăn nhẹ tại văn phòng.\n'
             'Các sự kiện hoạt động văn hóa nhân dịp lễ, tết:\n'
             '● Hoạt động kỉ niệm ngày thành lập công ty VCCorp\n'
             '● Hoạt động kỉ niệm và tặng quà sinh nhật CBCNV\n'
             '● Hoạt động kỉ niệm các ngày lễ, tết: ngày Quốc Tế Phụ Nữ 8/3, '
             'ngày Phụ Nữ Việt Nam 20/10, ngày Lễ Giáng Sinh, Tết Dương Lịch, '
             'Tết Trung Thu, Tết Thiếu Nhi...\n'
             '● Hội diễn và tiệc tổng kết Sum Up cuối năm\n'
             '● Giải bóng đá thường niên\n'
             '● Cuộc thi hoa hậu Miss VC thường niên\n'
             '● Radio Mõ Làng, chương trình phát thanh truyền thông nội bộ\n'
             '● Các hoạt động liên hoan team building theo nhóm, khối, bộ '
             'phận...\n'
             'Chương trình chăm sóc sức khỏe toàn diện VC Health Care\n'
             '● Thăm khám sức khỏe định kỳ hàng năm tại các bệnh viện cao cấp\n'
             '● Được tham gia các hoạt động trải nghiệm tư vấn chăm sóc sức '
             'khỏe từ các chuyên gia y tế, do công ty tổ chức theo hình thức '
             'các kênh trực tuyến và trực tiếp tại văn phòng.\n'
             'Chế độ nghỉ dưỡng và phúc lợi:\n'
             '● Chế độ nghỉ mát (theo quy chế của công ty).\n'
             '● Chế độ nghỉ phép (12 ngày nghỉ phép/năm theo quy định của Luật '
             'Lao Động).\n'
             '● Chế độ Hiếu, Hỉ, Sinh Con.',
 'company': 'VC Corp',
 'deadline': '',
 'description': '- Được đào tạo về lập trình Swift/ObjectiveC trong quá trình '
                'làm việc\n'
                ' - Xây dựng các Framework, Libs cho các dự án công ty \n'
                '- Tích hợp các API hoặc protocol khác để trao đổi dữ liệu với '
                'server \n'
                '- Thực hiện build Native Libs dựa trên một số công cụ build '
                'như (ninja, cmake, ...)',
 'experience': 'Dưới 1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/ios-developer/224475.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '8 - 20 triệu',
 'title': 'IOS Developer'}
2024-07-16 19:43:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/lap-trinh-vien-fullstack-nodejs-reactjs-aws/1404287.html?ta_source=ITJobs_LinkDetail> (failed 2 times): User timeout caused connection failure: Getting https://www.topcv.vn/viec-lam/lap-trinh-vien-fullstack-nodejs-reactjs-aws/1404287.html?ta_source=ITJobs_LinkDetail took longer than 180.0 seconds..
2024-07-16 19:43:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/qc-engineer/1404326.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:43:34 [scrapy.extensions.logstats] INFO: Crawled 69 pages (at 5 pages/min), scraped 65 items (at 5 items/min)
2024-07-16 19:43:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/lap-trinh-vien-php/1182827.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3)
2024-07-16 19:43:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/lap-trinh-vien-php/1182827.html?ta_source=ITJobs_LinkDetail>
{'benefits': 'Xem xét điều chỉnh lương khi cần thiết trong quá trình làm việc '
             'hoặc khi có thành tích vượt trội (không giới hạn số lần tăng '
             'lương trong năm). Các tiêu chí xét điều chỉnh lương:',
 'company': 'VC Corp',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/lap-trinh-vien-php/1182827.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '15 - 25 triệu',
 'title': 'Lập Trình Viên PHP'}
2024-07-16 19:43:44 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/pre-sales-engineer/1365077.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:43:46 [scrapy.core.engine] INFO: Error while handling downloader output
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 261, in _handle_downloader_output
    self.crawl(result)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 291, in crawl
    self._schedule_request(request, self.spider)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 308, in _schedule_request
    if not self.slot.scheduler.enqueue_request(request):  # type: ignore[union-attr]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 171, in enqueue_request
    self.queue.push(request)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 112, in push
    self.server.execute_command("ZADD", self.key, score, data)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 545, in execute_command
    return conn.retry.call_with_retry(
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/retry.py", line 49, in call_with_retry
    fail(error)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 549, in <lambda>
    lambda error: self._disconnect_raise(conn, error),
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 535, in _disconnect_raise
    raise error
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/retry.py", line 46, in call_with_retry
    return do()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 546, in <lambda>
    lambda: self._send_command_parse_response(
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 522, in _send_command_parse_response
    return self.parse_response(conn, command_name, **options)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 562, in parse_response
    response = connection.read_response()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 512, in read_response
    response = self._parser.read_response(disable_decoding=disable_decoding)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/_parsers/resp2.py", line 15, in read_response
    result = self._read_response(disable_decoding=disable_decoding)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/_parsers/resp2.py", line 25, in _read_response
    raw = self._buffer.readline()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/_parsers/socket.py", line 115, in readline
    self._read_from_socket()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/_parsers/socket.py", line 68, in _read_from_socket
    raise ConnectionError(SERVER_CLOSED_CONNECTION_ERROR)
redis.exceptions.ConnectionError: Connection closed by server.
2024-07-16 19:43:47 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 288, in connect
    self.on_connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 391, in on_connect
    self.read_response()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 512, in read_response
    response = self._parser.read_response(disable_decoding=disable_decoding)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/_parsers/resp2.py", line 15, in read_response
    result = self._read_response(disable_decoding=disable_decoding)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/_parsers/resp2.py", line 25, in _read_response
    raw = self._buffer.readline()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/_parsers/socket.py", line 115, in readline
    self._read_from_socket()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/_parsers/socket.py", line 68, in _read_from_socket
    raise ConnectionError(SERVER_CLOSED_CONNECTION_ERROR)
redis.exceptions.ConnectionError: Connection closed by server.

2024-07-16 19:43:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:43:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:43:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/ba-tieng-han-fresher/1405750.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3)
2024-07-16 19:43:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:43:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/ba-tieng-han-fresher/1405750.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'NTQ Solution',
 'deadline': '',
 'description': '',
 'experience': 'Dưới 1 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/ba-tieng-han-fresher/1405750.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Thoả thuận',
 'title': 'BA Tiếng Hàn (Fresher)'}
2024-07-16 19:43:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/junior-frontend/1405011.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:43:56 [scrapy.core.engine] INFO: Error while handling downloader output
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 276, in connect
    sock = self.retry.call_with_retry(
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/retry.py", line 46, in call_with_retry
    return do()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 277, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 639, in _connect
    raise err
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 627, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 261, in _handle_downloader_output
    self.crawl(result)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 291, in crawl
    self._schedule_request(request, self.spider)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 308, in _schedule_request
    if not self.slot.scheduler.enqueue_request(request):  # type: ignore[union-attr]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 171, in enqueue_request
    self.queue.push(request)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 112, in push
    self.server.execute_command("ZADD", self.key, score, data)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 542, in execute_command
    conn = self.connection or pool.get_connection(command_name, **options)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.
2024-07-16 19:43:56 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:43:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/project-manager-it/1255835.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3)
2024-07-16 19:44:02 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/project-manager-it/1255835.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'DI CHOI SOLUTION CO., LTD',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/project-manager-it/1255835.html?ta_source=ITJobs_LinkDetail',
 'location': 'Đà Nẵng',
 'requirements': '',
 'salary': '15 - 25 triệu',
 'title': 'Project Manager IT'}
2024-07-16 19:44:02 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/it-helpdesk/1405203.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:44:05 [scrapy.core.engine] INFO: Error while handling downloader output
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 276, in connect
    sock = self.retry.call_with_retry(
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/retry.py", line 46, in call_with_retry
    return do()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 277, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 639, in _connect
    raise err
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 627, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 261, in _handle_downloader_output
    self.crawl(result)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 291, in crawl
    self._schedule_request(request, self.spider)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 308, in _schedule_request
    if not self.slot.scheduler.enqueue_request(request):  # type: ignore[union-attr]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 171, in enqueue_request
    self.queue.push(request)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 112, in push
    self.server.execute_command("ZADD", self.key, score, data)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 542, in execute_command
    conn = self.connection or pool.get_connection(command_name, **options)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.
2024-07-16 19:44:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/java-developer/1405426.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3)
2024-07-16 19:44:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/brse-ky-su-cau-noi/1189609.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:44:15 [scrapy.core.engine] INFO: Error while handling downloader output
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 276, in connect
    sock = self.retry.call_with_retry(
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/retry.py", line 46, in call_with_retry
    return do()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 277, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 639, in _connect
    raise err
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 627, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 261, in _handle_downloader_output
    self.crawl(result)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 291, in crawl
    self._schedule_request(request, self.spider)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 308, in _schedule_request
    if not self.slot.scheduler.enqueue_request(request):  # type: ignore[union-attr]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 171, in enqueue_request
    self.queue.push(request)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 112, in push
    self.server.execute_command("ZADD", self.key, score, data)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 542, in execute_command
    conn = self.connection or pool.get_connection(command_name, **options)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.
2024-07-16 19:44:15 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/java-developer/1405426.html?ta_source=ITJobs_LinkDetail>
{'benefits': '– Fix 13 tháng lương\n'
             '– Thưởng performance 2 lần/năm vào tháng 6 và tháng 12\n'
             '– Review lương 2 lần/năm vào tháng 4 và tháng 10\n'
             '– Beauty care: 200.000 VND/người/tháng cho nhân viên nữ\n'
             '– Quỹ đào tạo 3.000.000 VND/người/năm\n'
             '– Phụ cấp thâm niên\n'
             '– Thưởng chứng chỉ tiếng Nhật và các loại chứng chỉ khác theo '
             'quy định (nếu có)\n'
             '– Bảo hiểm sức khỏe cho nhân viên từ 1 năm thâm niên\n'
             '– 12 ngày phép năm, BHXH/BHYT/BHTN đầy đủ theo quy định của Luật '
             'lao động\n'
             '– Nghỉ lễ Tết theo quy định Nhà nước và kèm theo thưởng cho các '
             'ngày lễ lớn trong năm: 30/4, 1/5, 2/9, Tết,...\n'
             '– Thời gian làm việc: Thứ 2 đến thứ 6 từ 8h-17h30 (nghỉ thứ 7, '
             'chủ nhật), thời gian chấm công (check in) linh hoạt từ 7h30-8h30',
 'company': 'Công ty cổ phần HBLab (Hedspi Brothers Lab)',
 'deadline': '',
 'description': '– Tham gia phát triển các ứng dụng trên nền tảng Java cho '
                'khách hàng Nhật Bản, duy trì và nâng cấp các tính năng của '
                'sản phẩm \n'
                '– Tư vấn giải pháp, thiết kế, xây dựng tạo ra các sản phẩm '
                'phần mềm tối ưu, phù hợp với nhu cầu của khách hàng\n'
                '– Làm việc theo sự phân công của trưởng nhóm/quản lý dự án, '
                'phối hợp giữa các nhóm để phát triển sản phẩm\n'
                '– Hỗ trợ các thành viên trong nhóm với các chức năng phức '
                'tạp, tham gia nhận xét, đánh giá source code của các thành '
                'viên trong nhóm\n'
                '– Nghiên cứu và áp dụng công nghệ, kiến trúc service mới tại '
                'các dự án lớn phù hợp với định hướng và chiến lược phát triển '
                'của Công ty',
 'experience': '3 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/java-developer/1405426.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '25 - 40 triệu',
 'title': 'Java Developer'}
2024-07-16 19:44:16 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-kinh-doanh/1404152.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:44:22 [scrapy.core.engine] INFO: Error while handling downloader output
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 276, in connect
    sock = self.retry.call_with_retry(
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/retry.py", line 46, in call_with_retry
    return do()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 277, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 639, in _connect
    raise err
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 627, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 261, in _handle_downloader_output
    self.crawl(result)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 291, in crawl
    self._schedule_request(request, self.spider)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 308, in _schedule_request
    if not self.slot.scheduler.enqueue_request(request):  # type: ignore[union-attr]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 171, in enqueue_request
    self.queue.push(request)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 112, in push
    self.server.execute_command("ZADD", self.key, score, data)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 542, in execute_command
    conn = self.connection or pool.get_connection(command_name, **options)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.
2024-07-16 19:44:22 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/it-comtor-tieng-nhat/1217394.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3)
2024-07-16 19:44:27 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/it-comtor-tieng-nhat/1217394.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty Cổ phần VNEXT SOFTWARE',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/it-comtor-tieng-nhat/1217394.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '15 - 25 triệu',
 'title': 'IT Comtor (Tiếng Nhật)'}
2024-07-16 19:44:27 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/golang-backend-engineer/1405952.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:44:31 [scrapy.core.engine] INFO: Error while handling downloader output
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 276, in connect
    sock = self.retry.call_with_retry(
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/retry.py", line 46, in call_with_retry
    return do()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 277, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 639, in _connect
    raise err
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 627, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 261, in _handle_downloader_output
    self.crawl(result)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 291, in crawl
    self._schedule_request(request, self.spider)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 308, in _schedule_request
    if not self.slot.scheduler.enqueue_request(request):  # type: ignore[union-attr]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 171, in enqueue_request
    self.queue.push(request)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 112, in push
    self.server.execute_command("ZADD", self.key, score, data)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 542, in execute_command
    conn = self.connection or pool.get_connection(command_name, **options)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.
2024-07-16 19:44:31 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:34 [scrapy.extensions.logstats] INFO: Crawled 74 pages (at 5 pages/min), scraped 70 items (at 5 items/min)
2024-07-16 19:44:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/java-backend-developer/360886.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3)
2024-07-16 19:44:38 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/java-backend-developer/360886.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty cổ phần Công nghệ Sapo',
 'deadline': '',
 'description': '',
 'experience': '3 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/java-backend-developer/360886.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': 'Tới 35 triệu',
 'title': 'Java Backend Developer'}
2024-07-16 19:44:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/back-end-nodejs-engineer/1405938.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:44:41 [scrapy.core.engine] INFO: Error while handling downloader output
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 276, in connect
    sock = self.retry.call_with_retry(
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/retry.py", line 46, in call_with_retry
    return do()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 277, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 639, in _connect
    raise err
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 627, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 261, in _handle_downloader_output
    self.crawl(result)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 291, in crawl
    self._schedule_request(request, self.spider)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 308, in _schedule_request
    if not self.slot.scheduler.enqueue_request(request):  # type: ignore[union-attr]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 171, in enqueue_request
    self.queue.push(request)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 112, in push
    self.server.execute_command("ZADD", self.key, score, data)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 542, in execute_command
    conn = self.connection or pool.get_connection(command_name, **options)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.
2024-07-16 19:44:41 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:47 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/nhan-vien-lap-trinh-net/1177415.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:44:47 [scrapy.core.engine] INFO: Error while handling downloader output
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 276, in connect
    sock = self.retry.call_with_retry(
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/retry.py", line 46, in call_with_retry
    return do()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 277, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 639, in _connect
    raise err
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 627, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 261, in _handle_downloader_output
    self.crawl(result)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 291, in crawl
    self._schedule_request(request, self.spider)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 308, in _schedule_request
    if not self.slot.scheduler.enqueue_request(request):  # type: ignore[union-attr]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 171, in enqueue_request
    self.queue.push(request)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 112, in push
    self.server.execute_command("ZADD", self.key, score, data)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 542, in execute_command
    conn = self.connection or pool.get_connection(command_name, **options)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.
2024-07-16 19:44:47 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:57 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.topcv.vn/viec-lam/senior-java-developer-english/1364099.html?ta_source=ITJobs_LinkDetail> (failed 1 times): 429 Unknown Status
2024-07-16 19:44:57 [scrapy.core.engine] INFO: Error while handling downloader output
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 276, in connect
    sock = self.retry.call_with_retry(
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/retry.py", line 46, in call_with_retry
    return do()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 277, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 639, in _connect
    raise err
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 627, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/defer.py", line 1078, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 261, in _handle_downloader_output
    self.crawl(result)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 291, in crawl
    self._schedule_request(request, self.spider)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 308, in _schedule_request
    if not self.slot.scheduler.enqueue_request(request):  # type: ignore[union-attr]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 171, in enqueue_request
    self.queue.push(request)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 112, in push
    self.server.execute_command("ZADD", self.key, score, data)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 542, in execute_command
    conn = self.connection or pool.get_connection(command_name, **options)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.
2024-07-16 19:44:57 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:44:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam/automation-tester/1404455.html?ta_source=ITJobs_LinkDetail> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3)
2024-07-16 19:45:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.topcv.vn/viec-lam/automation-tester/1404455.html?ta_source=ITJobs_LinkDetail>
{'benefits': '',
 'company': 'Công ty Cổ phần Công nghệ Phần mềm Tinh Vân',
 'deadline': '',
 'description': '',
 'experience': '2 năm',
 'how_to_apply': 'Ứng tuyển',
 'link': 'https://www.topcv.vn/viec-lam/automation-tester/1404455.html?ta_source=ITJobs_LinkDetail',
 'location': 'Hà Nội',
 'requirements': '',
 'salary': '20 - 27 triệu',
 'title': 'Automation Tester'}
2024-07-16 19:45:05 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=4> (referer: https://www.topcv.vn/viec-lam-it?sort=&skill_id=&skill_id_other=&keyword=&company_field=1&position=&salary=&page=3)
2024-07-16 19:45:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:20 [twisted] CRITICAL: Unhandled error in Deferred:
2024-07-16 19:45:20 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1115, in get_connection
    if connection.can_read():
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 490, in can_read
    return self._parser.can_read(timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/_parsers/base.py", line 128, in can_read
    return self._buffer and self._buffer.can_read(timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/_parsers/socket.py", line 95, in can_read
    return bool(self.unread_bytes()) or self._read_from_socket(
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/_parsers/socket.py", line 68, in _read_from_socket
    raise ConnectionError(SERVER_CLOSED_CONNECTION_ERROR)
redis.exceptions.ConnectionError: Connection closed by server.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 276, in connect
    sock = self.retry.call_with_retry(
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/retry.py", line 46, in call_with_retry
    return do()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 277, in <lambda>
    lambda: self._connect(), lambda error: self.disconnect(error)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 639, in _connect
    raise err
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 627, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/task.py", line 526, in _oneWorkUnit
    result = next(self._iterator)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/defer.py", line 102, in <genexpr>
    work = (callable(elem, *args, **named) for elem in iterable)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/scraper.py", line 298, in _process_spidermw_output
    self.crawler.engine.crawl(request=output)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 291, in crawl
    self._schedule_request(request, self.spider)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 308, in _schedule_request
    if not self.slot.scheduler.enqueue_request(request):  # type: ignore[union-attr]
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 166, in enqueue_request
    if not request.dont_filter and self.df.request_seen(request):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/dupefilter.py", line 102, in request_seen
    added = self.server.sadd(self.key, fp)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/commands/core.py", line 3315, in sadd
    return self.execute_command("SADD", name, *values)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 542, in execute_command
    conn = self.connection or pool.get_connection(command_name, **options)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1119, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.
2024-07-16 19:45:20 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:34 [scrapy.extensions.logstats] INFO: Crawled 77 pages (at 3 pages/min), scraped 72 items (at 2 items/min)
2024-07-16 19:45:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:45:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:46:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:46:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:46:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:46:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:46:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:46:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:46:34 [scrapy.extensions.logstats] INFO: Crawled 77 pages (at 0 pages/min), scraped 72 items (at 0 items/min)
2024-07-16 19:46:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:46:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:46:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:46:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:46:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:46:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:47:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:47:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:47:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:47:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:47:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:47:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:47:34 [scrapy.extensions.logstats] INFO: Crawled 77 pages (at 0 pages/min), scraped 72 items (at 0 items/min)
2024-07-16 19:47:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:47:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:47:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:47:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:47:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:47:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:48:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:48:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:48:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:48:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:48:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:48:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:48:34 [scrapy.extensions.logstats] INFO: Crawled 77 pages (at 0 pages/min), scraped 72 items (at 0 items/min)
2024-07-16 19:48:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:48:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:48:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:48:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:48:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:48:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:49:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:49:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:49:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:49:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:49:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:49:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:49:34 [scrapy.extensions.logstats] INFO: Crawled 77 pages (at 0 pages/min), scraped 72 items (at 0 items/min)
2024-07-16 19:49:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:49:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:49:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:49:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:49:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:49:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:50:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:50:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:50:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:50:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:50:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:50:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:50:34 [scrapy.extensions.logstats] INFO: Crawled 77 pages (at 0 pages/min), scraped 72 items (at 0 items/min)
2024-07-16 19:50:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:50:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:50:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:50:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:50:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:50:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:51:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:51:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:51:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:51:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:51:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:51:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:51:34 [scrapy.extensions.logstats] INFO: Crawled 77 pages (at 0 pages/min), scraped 72 items (at 0 items/min)
2024-07-16 19:51:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:51:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:51:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:51:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:51:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:51:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:52:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:52:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:52:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:52:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:52:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:52:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:52:34 [scrapy.extensions.logstats] INFO: Crawled 77 pages (at 0 pages/min), scraped 72 items (at 0 items/min)
2024-07-16 19:52:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:52:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:52:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:52:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:52:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:52:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:53:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:53:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:53:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:53:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:53:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:53:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:53:34 [scrapy.extensions.logstats] INFO: Crawled 77 pages (at 0 pages/min), scraped 72 items (at 0 items/min)
2024-07-16 19:53:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:53:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:53:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:53:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:53:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:53:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:54:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:54:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:54:14 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:54:19 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:54:24 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:54:29 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:54:34 [scrapy.extensions.logstats] INFO: Crawled 77 pages (at 0 pages/min), scraped 72 items (at 0 items/min)
2024-07-16 19:54:34 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:54:39 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:54:44 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:54:49 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:54:54 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:54:59 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:55:04 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:55:09 [twisted] CRITICAL: Unhandled Error
Traceback (most recent call last):
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 600, in run_forever
    self._run_once()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/base_events.py", line 1896, in _run_once
    handle._run()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/asyncio/events.py", line 80, in _run
    self._context.run(self._callback, *self._args)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/asyncioreactor.py", line 269, in _onTimer
    self.runUntilCurrent()
--- <exception caught here> ---
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/twisted/internet/base.py", line 1090, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/utils/reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy/core/engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/scrapy_redis/queue.py", line 123, in pop
    results, count = pipe.execute()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/client.py", line 1494, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 1109, in get_connection
    connection.connect()
  File "/Users/thaiminhhuy/.pyenv/versions/3.10.4/lib/python3.10/site-packages/redis/connection.py", line 282, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 61 connecting to localhost:6379. Connection refused.

2024-07-16 19:55:14 [scrapy.core.engine] INFO: Closing spider (finished)
2024-07-16 19:55:14 [scrapy.extensions.feedexport] INFO: Stored json feed (72 items) in: output.json
2024-07-16 19:55:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 1,
 'downloader/request_bytes': 173554,
 'downloader/request_count': 153,
 'downloader/request_method_count/GET': 153,
 'downloader/response_bytes': 14590137,
 'downloader/response_count': 152,
 'downloader/response_status_count/200': 77,
 'downloader/response_status_count/429': 75,
 'elapsed_time_seconds': 1360.123974,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 7, 16, 12, 55, 14, 146577, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 61711188,
 'httpcompression/response_count': 77,
 'item_scraped_count': 72,
 'log_count/CRITICAL': 160,
 'log_count/DEBUG': 230,
 'log_count/INFO': 42,
 'log_count/WARNING': 1,
 'memusage/max': 152662016,
 'memusage/startup': 63275008,
 'request_depth_max': 4,
 'response_received_count': 77,
 'retry/count': 76,
 'retry/reason_count/429 Unknown Status': 75,
 'retry/reason_count/twisted.internet.error.TimeoutError': 1,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued/redis': 152,
 'scheduler/enqueued/redis': 179,
 'start_time': datetime.datetime(2024, 7, 16, 12, 32, 34, 22603, tzinfo=datetime.timezone.utc)}
2024-07-16 19:55:14 [scrapy.core.engine] INFO: Spider closed (finished)
